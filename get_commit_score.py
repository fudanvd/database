from nltk.tokenize import sent_tokenize
import nltk
from nltk.corpus import stopwords
import string
import get_message
import datetime
import re
import functools

def compare(a,b):
    if a['score']<b['score']:
        return 1
    elif a['score']>b['score']:
        return -1
    else:
        return 0
weight = {
    'common_comment_words_num':0.1,
    'common_comment_words_rate':1,

    'matter_comment_words_num':0.5,
    'matter_comment_words_rate':5,

    'common_title_words_num':0.5,
    'common_title_words_rate':5,

    'matter_title_words_num':1,
    'matter_title_words_rate':10,

    'common_description_words_num':0.1,
    'common_description_words_rate':1,

    'matter_description_words_num':0.5,
    'matter_description_words_rate':5,

    'common_positions_words_num':0.5,
    'common_positions_words_rate':5,

    'matter_position_words_num':0.5,
    'matter_position_words_rate':5,

    'common_code_words_num':0.5,
    'common_code_words_rate':5,

    'matter_code_words_num':5,
    'matter_code_words_rate':10
}



def get_set(text = ''):
    text = text.translate(str.maketrans(string.punctuation, " " * len(string.punctuation)))

    # È¶ñÂÖàÈíàÂØπÊºèÊ¥ûÁöÑÊèèËø∞ÔºåÊàë‰ª¨Á≠õÈÄâÂá∫ÂÖ∂‰∏≠ÁöÑÂÖ≥ÈîÆÂ≠óÔºökey words
    stop_words = set(stopwords.words('english'))
    # Ëøô‰∏™stop_word_listÂ∫îËØ•ÂéªÈô§Ôºö
    #   1.Ê†áÁÇπ
    #   2.Êï∞Â≠ó
    #   3.Êó†Áî®ÁöÑËØ∏Â¶Ç theÔºåaÔºåx‰πãÁ±ªÁöÑËØçËØ≠
    #   4.Êú¨È¢ÜÂüü‰∏Ä‰∫õÂ∏∏ËßÅËØçËØ≠
    new_stop_words = [
        'version','Version','0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20',
        'a','an','A','An','The','the','index','allowing','x','‚Äô',',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%', '\'\'', '\'', '`', '``', '-', '--', '|', '\/',
        '‚Äú', '‚Äù','flaw','discovered','Elasticsearch','users','user','enables','elabled','Java','code','via','run','attackers','attacker','allows','allowed','security','machine','search','policy',
        'vulnerability'
    ]
    new_stopwords_list = stop_words.union(new_stop_words)


    word_tokens = nltk.tokenize.word_tokenize(text.strip())

    filtered_word = [w for w in word_tokens if not w in new_stopwords_list]

    return set(filtered_word)

if __name__ == "__main__":
    """
    CVE-2022-23708
    A flaw was discovered in Elasticsearch 7.17.0‚Äôs upgrade assistant, in which upgrading from version 6.x to 7.x would disable the in-built protections on the security index, allowing authenticated users with ‚Äú*‚Äù index permissions access to this index.
    """

    text = "A flaw was discovered in Elasticsearch 7.17.0‚Äôs upgrade assistant, in which upgrading from version 6.x to 7.x would disable the in-built protections on the security index, allowing authenticated users with ‚Äú*‚Äù index permissions access to this index."

    key_word_list = ['OOM', 'NPE']
    repository_url = 'https://github.com/elastic/elasticsearch/'
    dest_time = datetime.datetime.strptime("Mar 3, 2022", "%b %d, %Y")

    matter_words = [
        'null','pointer','dereference','buffer','overflow','overread','overwrite','overrun',
        'underflow','underread','underwrite','underrun','stack', 'heap', 'one','out','bound','array','range'
        'OOM','NPE','free','double','invalid','dangling','pointer','memory','resourrce','refcount','leak',
        'inifinite','endless','excessive','forever','loop','cursion','race','condition','deadlock','concurrent',
        'input','parameter','validation','invalid','parameters','check','integer','overflow','underflow','signed','shift','arithmetic','multiplication',
        'devided','zero','div/0','access','control','permission','information','data','exposure','disclosure','path',
        'directory','traversal','symbolic','link','cryptographic','injection','command','sql','SQL','cross','site','scripting',
        'fix','authentication','authenticate','uninitialized','missing','initialization'
    ]

    matter_words = set(matter_words)

    filtered_word = get_set(text)
    #print(filtered_word)

    uion_matterwords = matter_words.intersection(filtered_word)

    flag_matter_words = (len(uion_matterwords)>0)
    #print(flag_matter_words)

    key_word_list = filtered_word
    pull = get_message.get_key_pull(key_word_list, repository_url, dest_time)

    """
    pull = [
        {'origin_url': 'https://github.com/elastic/elasticsearch/pull/85217', 'comment': [" We recently had issues with EsThreadPoolExecutor throwing unexpected exceptions (in our case an AccessControlException) before the Runnable or AbstractRunnable has been submitted for execution. In the case of AbstractRunnable the task is not rejected and it causes some resources to leak. This pull request catches unexpected exceptions thrown when calling the EsThreadPoolExecutor#execute() method and logs a message. It also assert that this situation should never happen, and if that's the case an AssertionError is thrown in tests. ", " Looks good, a couple of thoughts:   Should we always do this, or only if command instanceof AbstractRunnable? If it's not AbstractRunnable then we expect the caller to handle exceptions anyway. Not sure of the exact guarantees on super.execute() here.   Could we emit the log message first so we can see the stack trace if this fails? Also could we include command in the message? Many commands have useful-ish string representations.   ", " LGTM, this should surface other unhandled exceptions (if there are any). But since there's some concerns around this change, I would wait for another reviewer approval. üëç ", ' LGTM '], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/85217/commits/6a870b05f66dac910a5fa1ad92371b648905c101', 'description': ['\n       Better logging when EsThreadPoolExecutor throws unexpected exceptions\n    '], 'position': ['server/src/main/java/org/elasticsearch/common/util/concurrent/EsThreadPoolExecutor.java'], 'code': {'cut': [], 'add': ['import org.apache.logging.log4j.LogManager;', 'import org.apache.logging.log4j.Logger;', 'import org.apache.logging.log4j.message.ParameterizedMessage;', '    private static final Logger logger = LogManager.getLogger(EsThreadPoolExecutor.class);', '', '        } catch (Exception e) {', '            assert false : "executor throws an exception (not a rejected execution exception) before the task has been submitted " + e;', '            logger.error(() -&gt; new ParameterizedMessage("[{}] unexpected exception when submitting task for execution", name), e);', '            throw e;']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/85217/commits/362eb1b6fde607461dbf57d2d60869c0db5e4f8f', 'description': ['\n       feedback\n    '], 'position': ['server/src/main/java/org/elasticsearch/common/util/concurrent/EsThreadPoolExecutor.java', 'server/src/test/java/org/elasticsearch/common/util/concurrent/EsThreadPoolExecutorTests.java'], 'code': {'cut': [' command = wrapRunnable(command);', '            super.execute(command);', '        } catch (EsRejectedExecutionException ex) {', '            if (command instanceof AbstractRunnable) {', '                // If we are an abstract runnable we can handle the rejection', "                // directly and don't need to rethrow it.", '                    ((AbstractRunnable) command).onRejection(ex);', '                    ((AbstractRunnable) command).onAfter();', '', '                throw ex;', '        } catch (Exception e) {', '            assert false : "executor throws an exception (not a rejected execution exception) before the task has been submitted " + e;', '            logger.error(() -&gt; new ParameterizedMessage("[{}] unexpected exception when submitting task for execution", name), e);', '            throw e;'], 'add': [' final Runnable wrappedRunnable = wrapRunnable(command);', '            super.execute(wrappedRunnable);', '        } catch (Exception e) {', '            if (wrappedRunnable instanceof AbstractRunnable abstractRunnable) {', '                    // If we are an abstract runnable we can handle the exception', "                    // directly and don't need to rethrow it, but we log and assert", '                    // any unexpected exception first.', '                    if (e instanceof EsRejectedExecutionException == false) {', '                        logException(abstractRunnable, e);', '                    }', '                    abstractRunnable.onRejection(e);', '                    abstractRunnable.onAfter();', '                throw e;', '    // package-visible for testing', '    void logException(AbstractRunnable r, Exception e) {', '        logger.error(() -&gt; new ParameterizedMessage("[{}] unexpected exception when submitting task [{}] for execution", name, r), e);', '        assert false : "executor throws an exception (not a rejected execution exception) before the task has been submitted " + e;', '    }', '', 'import java.security.AccessControlException;', 'import java.util.concurrent.LinkedBlockingQueue;', 'import java.util.concurrent.TimeUnit;', 'import java.util.concurrent.atomic.AtomicReference;', 'import static org.hamcrest.Matchers.equalTo;', 'import static org.hamcrest.Matchers.nullValue;', 'import static org.hamcrest.Matchers.sameInstance;', '    public void testExecuteThrowsException() {', '        final RuntimeException exception = randomFrom(', '            new RuntimeException("unexpected"),', '            new AccessControlException("unexpected"),', '            new EsRejectedExecutionException("unexpected")', '        );', '', '        final ThrowingEsThreadPoolExecutor executor = new ThrowingEsThreadPoolExecutor(getTestName(), 0, 1, exception);', '        try {', '            final AtomicBoolean doRun = new AtomicBoolean();', '            final AtomicBoolean onAfter = new AtomicBoolean();', '            final AtomicReference&lt;Exception&gt; onFailure = new AtomicReference&lt;&gt;();', '            final AtomicReference&lt;Exception&gt; onRejection = new AtomicReference&lt;&gt;();', '', '            executor.execute(new AbstractRunnable() {', '                @Override', '                public void onFailure(Exception e) {', '                    onFailure.set(e);', '                }', '', '                @Override', '                public void onRejection(Exception e) {', '                    onRejection.set(e);', '                }', '', '                @Override', '                protected void doRun() {', '                    doRun.set(true);', '                }', '', '                @Override', '                public void onAfter() {', '                    onAfter.set(true);', '                }', '            });', '', '            assertThat(doRun.get(), equalTo(false));', '            assertThat(onAfter.get(), equalTo(true));', '            assertThat(onFailure.get(), nullValue());', '            assertThat(onRejection.get(), sameInstance(exception));', '            assertThat(', '                executor.lastLoggedException.get(),', '                exception instanceof EsRejectedExecutionException ? nullValue() : sameInstance(exception)', '            );', '        } finally {', '            terminate(executor);', '        }', '    }', '', '    /**', '     * EsThreadPoolExecutor that throws a given exception, preventing {@link Runnable} to be added to the thread pool work queue.', '     */', '    private class ThrowingEsThreadPoolExecutor extends EsThreadPoolExecutor {', '', '        final AtomicReference&lt;Exception&gt; lastLoggedException = new AtomicReference&lt;&gt;();', '', '        ThrowingEsThreadPoolExecutor(String name, int corePoolSize, int maximumPoolSize, RuntimeException exception) {', '            super(name, corePoolSize, maximumPoolSize, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;() {', '                @Override', '                public boolean offer(Runnable r) {', '                    throw exception;', '                }', '            }, EsExecutors.daemonThreadFactory("test"), new ThreadContext(Settings.EMPTY));', '        }', '', '        @Override', '        void logException(AbstractRunnable task, Exception e) {', '            lastLoggedException.set(e);', '        }', '    }']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/85217/commits/1d26f9a8afbaf6dfc9389616638e3ffb508fe16b', 'description': ["\n       Merge branch 'master' into assertion-error-in-execute\n    "], 'position': ['server/src/main/java/org/elasticsearch/common/util/concurrent/EsThreadPoolExecutor.java'], 'code': {'cut': ['        } catch (Exception ex) {', '            if (command instanceof AbstractRunnable) {', '                assert false : ex;', '                logger.error(new ParameterizedMessage("execution of [{}] failed", wrappedCommand), ex);', '            }', '            throw ex;'], 'add': []}}], 'title': 'Better logging when EsThreadPoolExecutor throws unexpected exceptions'}
        , {'origin_url': 'https://github.com/elastic/elasticsearch/pull/84878', 'comment': [' The LinearizabilityChecker has one use of hppc, where it uses a Long to Object map. Given that the rest of the maps in the Cache class are Java Maps, and this is only for testing, hppc does not seem necessary. This commit converts the usage to Map. relates #84735 ', ' LGTM, thanks for verifying this thoroughly. '], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/84878/commits/cc7542c70e32236323ec617b90fbf82fd90a996c', 'description': ['\n       Remove hppc from LinearizabilityChecker\n    '], 'position': ['...ramework/src/main/java/org/elasticsearch/cluster/coordination/LinearizabilityChecker.java'], 'code': {'cut': ['import com.carrotsearch.hppc.LongObjectHashMap;', '', '        private final LongObjectHashMap&lt;Set&lt;Object&gt;&gt; smallMap = new LongObjectHashMap&lt;&gt;();', '            int index = smallMap.indexOf(bits);', '            Set&lt;Object&gt; states;', '            if (index &lt; 0) {', '                states = Collections.singleton(state);', '                Set&lt;Object&gt; oldStates = smallMap.indexGet(index);', '            if (index &lt; 0) {', '                smallMap.indexInsert(index, bits, states);', '            } else {', '                smallMap.indexReplace(index, states);', '            }'], 'add': ['        private final Map&lt;Long, Set&lt;Object&gt;&gt; smallMap = new HashMap&lt;&gt;();', '            Set&lt;Object&gt; states = smallMap.get(bits);', '            if (states == null) {', '                states = Set.of(state);', '                Set&lt;Object&gt; oldStates = states;', '            smallMap.put(bits, states);']}}], 'title': 'Remove hppc from LinearizabilityChecker'}
        , {'origin_url': 'https://github.com/elastic/elasticsearch/pull/84010', 'comment': [' In the process of full restart, OOM problems are often encountered. After dump analysis and we found the following problems.  In the process of fetching data, the master will ask each data whether it owns the shard, and all the returned results of the node will be saved in the map&lt;nodeId, nodeResponse&gt; in AsyncShardFetch. In most cases, a shard only has data on several nodes, but the intermediate result map will still save the return results of all nodes. In this MR, we only save valid intermediate result of node responses and ignore the node responses that does not hold the shard at all. It is proved to be successfully in our company and the OOM issue is gone after the optimization. '], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/84010/commits/e37d3e1aabe5afb8125bb4245902195fc2773035', 'description': ['\n       Remove redundant response of empty result in AsyncShardFetch to avoid‚Ä¶\n    '], 'position': ['...java/org/elasticsearch/action/admin/indices/shards/TransportIndicesShardStoresAction.java', 'server/src/main/java/org/elasticsearch/gateway/AsyncShardFetch.java', 'server/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java'], 'code': {'cut': ['                super(logger, type, shardId, customDataPath, action);', '        Lister&lt;? extends BaseNodesResponse&lt;T&gt;, T&gt; action', '            if (shardCache.containsKey(node.getId()) == false) {', '            Lister&lt;? extends BaseNodesResponse&lt;T&gt;, T&gt; action', '            super(logger, type, shardId, customDataPath, action);', '                    lister', '                    lister'], 'add': ['                super(logger, type, shardId, customDataPath, action, x -&gt; true);', 'import java.util.function.Predicate;', '    private Predicate&lt;T&gt; validResultPredicate;', '    private Set&lt;DiscoveryNode&gt; completeNodes = new HashSet&lt;&gt;();', '        Lister&lt;? extends BaseNodesResponse&lt;T&gt;, T&gt; action,', '        Predicate&lt;T&gt; validResultPredicate', '        this.validResultPredicate = validResultPredicate;', '                        completeNodes.add(response.getNode());', '                        if (!validResultPredicate.test(response)) {', '                            cache.remove(response.getNode().getId());', '                        }', '        completeNodes.remove(nodeId);', '            if (completeNodes.contains(node.getId()) == false &amp;&amp; shardCache.containsKey(node.getId()) == false) {', '        completeNodes.removeIf(node -&gt; !nodes.nodeExists(node.getId()));', 'import java.util.function.Predicate;', '            Lister&lt;? extends BaseNodesResponse&lt;T&gt;, T&gt; action,', '            Predicate&lt;T&gt; validResultPredicate', '            super(logger, type, shardId, customDataPath, action, validResultPredicate);', '                    lister,', '                    result -&gt; result.allocationId() != null', '                    lister,', '                    result -&gt; !result.storeFilesMetadata().isEmpty()']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/84010/commits/6bd96e67355fb0525d3bb0089c29b26d63048a82', 'description': ['\n       Add changelog\n    '], 'position': ['docs/changelog/84010.yaml'], 'code': {'cut': [], 'add': ['pr: 84010', 'summary: Remove redundant response of empty result in AsyncShardFetch', 'area: Distributed', 'type: bug', 'issues: []']}}], 'title': 'Remove redundant response of empty result in AsyncShardFetch to avoid OOM issue'}
        , {'origin_url': 'https://github.com/elastic/elasticsearch/pull/83832', 'comment': [' The issue we are addressing We are trying to avoid overwhelming the coordinating node of a stats or a recovery request in the case where other nodes are having troubles. See #51992 :  if a single node becomes unresponsive for a few minutes then we could see a couple hundred requests build up and in a decent sized cluster each could consume many MBs of heap on the coordinating node.  Approach We are introducing a limit on how many stats and recovery requests a node can coordinate concurrently. When we receive one too many of this requests the node rejects with a 409. We are not concerned with further handling of this error because we assume that these requests would have timed out anyway. The limit is configurable as a cluster setting. The choice to have one limit that would apply to both requests was made for the sake of simplicity. This is seen as a protective mechanism that is triggered only to defend the node if the cluster is having troubles and not to rate limit requests when things are going well. We could alternatively create separate limits for each requests we want to bound, if there are objections to this approach. Implementation details We introduce StatsRequestLimiter which uses AdjustableSemaphore to bound the requests. Via the method tryToExecute(Task task, Request request, ActionListener&lt;Response&gt; listener, TriConsumer&lt;Task, Request, ActionListener&lt;Response&gt;&gt; execute), this class orchestrates all aspects of pushing back, it checks the semaphore, it tracks metrics and handles exceptions. Affected actions:  IndicesStatsActions RecoveryAction IndicesSegmentsAction NodesStatsAction ClusterStatsAction NodesInfoAction NodesUsageAction  Resolves #51992 ', ' Thanks for working on this Mary, I left a few small comments. Another question I have is, is this something that it makes sense to track as a stats metric? It seems like it might be useful to have a "number of times diagnostics were requested but rejected" similar to the way that we track threadpool rejections. Having something like that would be useful for an administrator/support to be able to tweak the setting to help when stats requests are overloading a cluster. If that sounds useful maybe we can think about it as a follow-up to this? ', " I'm undecided whether we should exclude requests that specify target indices. Monitoring clients just request everything, and these are the ones that cause trouble when they build up, but a client that just asks for stats about a single index will cause fewer problems; moreover such a client might want to make many more requests in parallel. There's a few TransportNodesAction subclasses that we might also want to consider limiting, particularly cluster stats and node stats. ", ' Sorry for the quick-fire reviews, this one is just alternative naming suggestions. ', " This generally looks good to me, I left a couple more comments, but I'd also like to wait for David's review also (and confirmation about the double-release comment) before merging ", " I think (but I'm not sure) this can double-invoke the release.run(). Since the request wraps the release::run before the original listener, the executeAction can run, the first invocation of release.run() can happen (the one from runBefore), then the original listener can throw an exception, which would cause the success boolean not to be updated, and then the release.run() in the finally block would run a second time. I guess it depends on whether ActionListeners are expected to ever throw exceptions (@DaveCTurner can probably clarify on this point), but if they can, then maybe the runBefore call could do something like () -&gt; { success.getAndSet(true); release.run(); } and then it wouldn't have the potential for invoking twice? (if they can't, then this is probably a moot point) ", ' I am processing the possibilities but I do not have an answer yet. Coming asap ', " Yes I believe it's possible that executeAction might throw an exception but still go on to complete its listener. I mean it probably shouldn't, but in general we're ok with completing an ActionListener multiple times so we don't protect against this. However here the release runnable is a RunOnce so it doesn't matter. ", " I will start with the suggestion that the runBefore() does something like this () -&gt; { success.getAndSet(true); release.run(); } because I feel more confident about my analysis :). I believe this will cause double invocation in almost all cases, because:  executeAction introduces the runBefore to run before the original action listener starts whatever async needs to be run and finishes Chances are by this point, the async work hasn't finished yet, which means the success is false and the finally will run the release.run() effectively releasing the semaphore while the node is still coordinating When the async work finishes, the original listener will be notified and the release.run() will be called again.  Now let's go to the trickier part, it's not clear to me yet where could the original listener throw an exception. If I look at the code of the RunBeforeActionListener:         @Override         public void onResponse(T response) {             try {                 runBefore.run();             } catch (Exception ex) {                 super.onFailure(ex);                 return;             }             delegate.onResponse(response);         }   Similar the failure is being handled,  the release will be called even if the original listener has an error. I would expect that the only situation where this can go wrong, is if the listener is never completed and the executeAction finished. But this effectively would mean that the node is still coordinating so we have a different problem then right? Did I address your concern properly? PS: I do not know if my understanding is correct or complete, so I would also appreciate @DaveCTurner input) ", " I think there's no need for any changes in this area - RunOnce already does what is needed. It's not just about completing the listener once but also releasing things in the finally block, you also need to protect against completing the listener multiple times. But we already do the right thing here. ", " Yep, totally didn't notice that the release was a RunOnce, that's fine then and no worries about this. ", " Yes I believe it's possible that executeAction might throw an exception but still go on to complete its listener. I mean it probably shouldn't, but in general we're ok with completing an ActionListener multiple times so we don't protect against this. However here the release runnable is a RunOnce so it doesn't matter. ", ' LGTM, thanks for iterating Mary! '], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/bf5a001474e22856cd6423ff7536113ec741cbc4', 'description': ['\n       Introduce permits service to track the bounded req\n    '], 'position': ['...java/org/elasticsearch/action/support/broadcast/node/BoundedDiagnosticRequestPermits.java', 'server/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java', 'server/src/main/java/org/elasticsearch/node/Node.java', '...org/elasticsearch/action/support/broadcast/node/BoundedDiagnosticRequestPermitsTests.java'], 'code': {'cut': ['        DataTier.ENFORCE_DEFAULT_TIER_PREFERENCE_SETTING'], 'add': ['/*', ' * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one', ' * or more contributor license agreements. Licensed under the Elastic License', ' * 2.0 and the Server Side Public License, v 1; you may not use this file except', ' * in compliance with, at your election, the Elastic License 2.0 or the Server', ' * Side Public License, v 1.', ' */', '', 'package org.elasticsearch.action.support.broadcast.node;', '', 'import org.elasticsearch.common.settings.ClusterSettings;', 'import org.elasticsearch.common.settings.Setting;', 'import org.elasticsearch.common.settings.Settings;', 'import org.elasticsearch.common.util.concurrent.AdjustableSemaphore;', '', '/**', ' * This class guards the amount of bounded diagnostic requests a node can concurrently coordinate.', ' */', 'public class BoundedDiagnosticRequestPermits {', '', '    public static final Setting&lt;Integer&gt; MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE = Setting.intSetting(', '        "cluster.max_concurrent_bounded_diagnostic_requests_per_node",', '        50,', '        1,', '        Setting.Property.NodeScope,', '        Setting.Property.Dynamic', '    );', '', '    private final AdjustableSemaphore maxConcurrentBoundedDiagnosticRequestsPerNodeSemaphore;', '    private volatile Integer maxConcurrentBoundedDiagnosticRequestsPerNode;', '', '    public BoundedDiagnosticRequestPermits(Settings settings, ClusterSettings clusterSettings) {', '        this.maxConcurrentBoundedDiagnosticRequestsPerNode = MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.get(settings);', '        this.maxConcurrentBoundedDiagnosticRequestsPerNodeSemaphore = new AdjustableSemaphore(', '            this.maxConcurrentBoundedDiagnosticRequestsPerNode,', '            false', '        );', '        clusterSettings.addSettingsUpdateConsumer(', '            MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE,', '            this::setMaxConcurrentBoundedDiagnosticRequestsPerNode', '        );', '    }', '', '    private void setMaxConcurrentBoundedDiagnosticRequestsPerNode(int maxConcurrentBoundedDiagnosticRequestsPerNode) {', '        this.maxConcurrentBoundedDiagnosticRequestsPerNode = maxConcurrentBoundedDiagnosticRequestsPerNode;', '        this.maxConcurrentBoundedDiagnosticRequestsPerNodeSemaphore.setMaxPermits(maxConcurrentBoundedDiagnosticRequestsPerNode);', '    }', '', '    public boolean tryAcquire() {', '        return maxConcurrentBoundedDiagnosticRequestsPerNodeSemaphore.tryAcquire();', '    }', '', '    public void release() {', '        maxConcurrentBoundedDiagnosticRequestsPerNodeSemaphore.release();', '    }', '}', 'import org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits;', '        DataTier.ENFORCE_DEFAULT_TIER_PREFERENCE_SETTING,', '        BoundedDiagnosticRequestPermits.MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE', 'import org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits;', '            final BoundedDiagnosticRequestPermits broadcastedRequestPermits = new BoundedDiagnosticRequestPermits(', '                settings,', '                settingsModule.getClusterSettings()', '            );', '', '                b.bind(BoundedDiagnosticRequestPermits.class).toInstance(broadcastedRequestPermits);', '/*', ' * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one', ' * or more contributor license agreements. Licensed under the Elastic License', ' * 2.0 and the Server Side Public License, v 1; you may not use this file except', ' * in compliance with, at your election, the Elastic License 2.0 or the Server', ' * Side Public License, v 1.', ' */', '', 'package org.elasticsearch.action.support.broadcast.node;', '', 'import org.elasticsearch.common.settings.ClusterSettings;', 'import org.elasticsearch.common.settings.Settings;', 'import org.elasticsearch.test.ESTestCase;', '', 'import static org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits.MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE;', '', 'public class BoundedDiagnosticRequestPermitsTests extends ESTestCase {', '', '    public void testGrantsPermitsUpToMaxPermits() {', '        int maxPermits = randomIntBetween(1, 5);', '        ClusterSettings clusterSettings = new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);', '        BoundedDiagnosticRequestPermits boundedDiagnosticRequestPermits = new BoundedDiagnosticRequestPermits(', '            Settings.builder().put(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey(), maxPermits).build(),', '            clusterSettings', '        );', '', '        for (int i = 0; i &lt; maxPermits; i++) {', '            assertTrue(boundedDiagnosticRequestPermits.tryAcquire());', '        }', '        assertFalse(boundedDiagnosticRequestPermits.tryAcquire());', '        boundedDiagnosticRequestPermits.release();', '        assertTrue(boundedDiagnosticRequestPermits.tryAcquire());', '    }', '', '    public void testBroadcastRequestPermitCanBeDynamicallyUpdated() {', '        ClusterSettings clusterSettings = new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);', '        BoundedDiagnosticRequestPermits boundedDiagnosticRequestPermits = new BoundedDiagnosticRequestPermits(', '            Settings.builder().put(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey(), 1).build(),', '            clusterSettings', '        );', '', '        assertTrue(boundedDiagnosticRequestPermits.tryAcquire());', '        assertFalse(boundedDiagnosticRequestPermits.tryAcquire());', '', '        clusterSettings.applySettings(Settings.builder().put(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey(), 2).build());', '', '        assertTrue(boundedDiagnosticRequestPermits.tryAcquire());', '', '        clusterSettings.applySettings(Settings.builder().put(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey(), 1).build());', '', '        assertFalse(boundedDiagnosticRequestPermits.tryAcquire());', '        boundedDiagnosticRequestPermits.release();', '        boundedDiagnosticRequestPermits.release();', '', '        assertTrue(boundedDiagnosticRequestPermits.tryAcquire());', '        assertFalse(boundedDiagnosticRequestPermits.tryAcquire());', '    }', '', '    public void testMaxConcurrentBroadcastRequestsPerNodeIsValidated() {', '        ClusterSettings clusterSettings = new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);', '        Settings invalidSetting = Settings.builder().put(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey(), 0).build();', '        expectThrows(IllegalArgumentException.class, () -&gt; new BoundedDiagnosticRequestPermits(invalidSetting, clusterSettings));', '        new BoundedDiagnosticRequestPermits(', '            Settings.builder().put(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey(), 1).build(),', '            clusterSettings', '        );', '        expectThrows(', '            IllegalArgumentException.class,', '            () -&gt; clusterSettings.applySettings(', '                Settings.builder().put(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey(), 0).build()', '            )', '        );', '    }', '}']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/466114936d71704577b1ea7570b5495a3fe96051', 'description': ['\n       Bound recovery &amp; stats requests\n    '], 'position': ['docs/reference/modules/cluster/misc.asciidoc', '...rc/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java', '...c/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java', '...java/org/elasticsearch/action/support/broadcast/node/BoundedDiagnosticRequestPermits.java', '...ava/org/elasticsearch/action/support/broadcast/node/TransportBoundedDiagnosticAction.java'], 'code': {'cut': ['Shards for closed indices do not count toward this limit. Defaults to `1000`.', '{es} rejects any request that creates more shards than this limit allows. For', '(&lt;&lt;dynamic-cluster-setting,Dynamic&gt;&gt;)', 'Limits the total number of primary and replica frozen shards for the cluster.', 'Shards for closed indices do not count toward this limit. Defaults to `3000`.', '`100` and three frozen data nodes has a frozen shard limit of 300. If the', 'cluster already contains 296 shards, {es} rejects any request that adds five or', 'more frozen shards to the cluster.', 'NOTE: These setting do not limit shards for individual nodes. To limit the', 'number of shards for each node, use the', 'This can be used to store arbitrary, infrequently-changing data about the cluster', 'without the need to create an index to store it. This data may be stored using', 'any key prefixed with `cluster.metadata.`. For example, to store the email', 'address of the administrator of a cluster under the key `cluster.metadata.administrator`,', 'issue this request:', 'confidential information. Any information stored in user-defined cluster', 'import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;', 'public class TransportRecoveryAction extends TransportBroadcastByNodeAction&lt;RecoveryRequest, RecoveryResponse, RecoveryState&gt; {', '        IndexNameExpressionResolver indexNameExpressionResolver', '            ThreadPool.Names.MANAGEMENT', 'import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;', 'public class TransportIndicesStatsAction extends TransportBroadcastByNodeAction&lt;IndicesStatsRequest, IndicesStatsResponse, ShardStats&gt; {', '        IndexNameExpressionResolver indexNameExpressionResolver', '            ThreadPool.Names.MANAGEMENT', ' 50,'], 'add': ['Shards for closed indices do not count toward this limit.Defaults to `1000`.', '{es} rejects any request that creates more shards than this limit allows.For', '(&lt;&lt;dynamic-cluster-setting,Dynamic&gt;&gt;) Limits the total number of primary and replica frozen shards for the cluster.', 'Shards for closed indices do not count toward this limit.Defaults to `3000`.', '`100` and three frozen data nodes has a frozen shard limit of 300. If the cluster already contains 296 shards, {es} rejects any request that adds five or more frozen shards to the cluster.', 'NOTE: These setting do not limit shards for individual nodes.', 'To limit the number of shards for each node, use the', '[[bounded-diagnostic-requests-limit]]', '===== Bounded diagnostic requests limit', '', 'A diagnostic request might require information from all nodes to be aggregated before it returns to the user.', 'These calls can be heavy and they put extra pressure on the coordinating node (the node collecting the responses from all the nodes), for this reason there is a limit on the concurrent requests that a node can coordinate.', 'Currently, the only bounded diagnostic requests are &lt;&lt;indices-stats, index stats&gt;&gt;', 'and &lt;&lt;indices-recovery, recovery&gt;&gt; APIs.', '', '--', '', '[[cluster-max-concurrent-bounded-diagnostic-requests-per-node]]', '`cluster.max_concurrent_bounded_diagnostic_requests_per_node`::', '+', '--', '', '(&lt;&lt;dynamic-cluster-setting,Dynamic&gt;&gt;) Limits the bounded diagnostic requests a coordinating node can concurrently handle.', '', 'This can be used to store arbitrary, infrequently-changing data about the cluster without the need to create an index to store it.', 'This data may be stored using any key prefixed with `cluster.metadata.`.', 'For example, to store the email address of the administrator of a cluster under the key `cluster.metadata.administrator`, issue this request:', 'confidential information.Any information stored in user-defined cluster', 'import org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits;', 'import org.elasticsearch.action.support.broadcast.node.TransportBoundedDiagnosticAction;', 'public class TransportRecoveryAction extends TransportBoundedDiagnosticAction&lt;RecoveryRequest, RecoveryResponse, RecoveryState&gt; {', '        IndexNameExpressionResolver indexNameExpressionResolver,', '        BoundedDiagnosticRequestPermits boundedDiagnosticRequestPermits', '            ThreadPool.Names.MANAGEMENT,', '            boundedDiagnosticRequestPermits', 'import org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits;', 'import org.elasticsearch.action.support.broadcast.node.TransportBoundedDiagnosticAction;', 'public class TransportIndicesStatsAction extends TransportBoundedDiagnosticAction&lt;IndicesStatsRequest, IndicesStatsResponse, ShardStats&gt; {', '        IndexNameExpressionResolver indexNameExpressionResolver,', '        BoundedDiagnosticRequestPermits boundedDiagnosticRequestPermits', '            ThreadPool.Names.MANAGEMENT,', '            boundedDiagnosticRequestPermits', ' 20,', '/*', ' * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one', ' * or more contributor license agreements. Licensed under the Elastic License', ' * 2.0 and the Server Side Public License, v 1; you may not use this file except', ' * in compliance with, at your election, the Elastic License 2.0 or the Server', ' * Side Public License, v 1.', ' */', '', 'package org.elasticsearch.action.support.broadcast.node;', '', 'import org.elasticsearch.action.ActionListener;', 'import org.elasticsearch.action.support.ActionFilters;', 'import org.elasticsearch.action.support.broadcast.BroadcastRequest;', 'import org.elasticsearch.action.support.broadcast.BroadcastResponse;', 'import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;', 'import org.elasticsearch.cluster.service.ClusterService;', 'import org.elasticsearch.common.io.stream.Writeable;', 'import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;', 'import org.elasticsearch.common.util.concurrent.RunOnce;', 'import org.elasticsearch.tasks.Task;', 'import org.elasticsearch.transport.TransportService;', '', '/**', ' * A bounded diagnostic action represents an action that aggregates information from all nodes, mainly for diagnostic purposes, and there is', ' * a limit on how many such requests a node can coordinate concurrently. The need for such a class of actions is to protect the node from', ' * getting overwhelmed when another load is slow to respond. The focus is on diagnostic requests because they tend to be executed', ' * periodically.', ' *', ' * @param &lt;Request&gt;              the underlying client request', ' * @param &lt;Response&gt;             the response to the client request', ' * @param &lt;ShardOperationResult&gt; per-shard operation results', ' */', 'public abstract class TransportBoundedDiagnosticAction&lt;', '    Request extends BroadcastRequest&lt;Request&gt;,', '    Response extends BroadcastResponse,', '    ShardOperationResult extends Writeable&gt; extends TransportBroadcastByNodeAction&lt;Request, Response, ShardOperationResult&gt; {', '', '    private final BoundedDiagnosticRequestPermits boundedDiagnosticRequestPermits;', '', '    public TransportBoundedDiagnosticAction(', '        String actionName,', '        ClusterService clusterService,', '        TransportService transportService,', '        ActionFilters actionFilters,', '        IndexNameExpressionResolver indexNameExpressionResolver,', '        Writeable.Reader&lt;Request&gt; request,', '        String executor,', '        BoundedDiagnosticRequestPermits boundedDiagnosticRequestPermits', '    ) {', '        this(', '            actionName,', '            clusterService,', '            transportService,', '            actionFilters,', '            indexNameExpressionResolver,', '            request,', '            executor,', '            true,', '            boundedDiagnosticRequestPermits', '        );', '    }', '', '    public TransportBoundedDiagnosticAction(', '        String actionName,', '        ClusterService clusterService,', '        TransportService transportService,', '        ActionFilters actionFilters,', '        IndexNameExpressionResolver indexNameExpressionResolver,', '        Writeable.Reader&lt;Request&gt; request,', '        String executor,', '        boolean canTripCircuitBreaker,', '        BoundedDiagnosticRequestPermits boundedDiagnosticRequestPermits', '    ) {', '        super(', '            actionName,', '            clusterService,', '            transportService,', '            actionFilters,', '            indexNameExpressionResolver,', '            request,', '            executor,', '            canTripCircuitBreaker', '        );', '', '        this.boundedDiagnosticRequestPermits = boundedDiagnosticRequestPermits;', '    }', '', '    @Override', '    protected void doExecute(Task task, Request request, ActionListener&lt;Response&gt; listener) {', '        if (boundedDiagnosticRequestPermits.tryAcquire()) {', '            final Runnable release = new RunOnce(boundedDiagnosticRequestPermits::release);', '            boolean success = false;', '            try {', '                super.doExecute(task, request, ActionListener.runBefore(listener, release::run));', '                success = true;', '            } finally {', '                if (success == false) {', '                    release.run();', '                }', '            }', '        } else {', '            listener.onFailure(new EsRejectedExecutionException("too many bounded diagnostic requests"));', '        }', '    }', '}']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/e389f7a5a540405528e71b1d8c2c2db984155eaf', 'description': ['\n       Update docs/changelog/83832.yaml\n    '], 'position': ['docs/changelog/83832.yaml'], 'code': {'cut': [], 'add': ['pr: 83832', 'summary: Push back excessive requests for stats', 'area: Stats', 'type: enhancement', 'issues: []']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/4471b47f0a528e02b6e49422b1def28dec4c9af7', 'description': ['\n       Extend stats limit to facilitate a test\n    '], 'position': ['server/src/internalClusterTest/java/org/elasticsearch/indices/stats/IndexStatsIT.java'], 'code': {'cut': ['        for (int i = 0; i &lt; numberOfStatsThreads; i++) {', '            final Thread thread = new Thread(() -&gt; {', '                try {', '                    barrier.await();', '                } catch (final BrokenBarrierException | InterruptedException e) {', '                    failed.set(true);', '                    executionFailures.get().add(e);', '                    latch.countDown();', '                }', '                final IndicesStatsRequest request = new IndicesStatsRequest();', '                request.all();', '                request.indices(new String[0]);', '                while (stop.get() == false) {', '                        final IndicesStatsResponse response = client().admin().indices().stats(request).get();', '                        if (response.getFailedShards() &gt; 0) {', '                            failed.set(true);', '                            shardFailures.get().addAll(Arrays.asList(response.getShardFailures()));', '                            latch.countDown();', '                        }', '                    } catch (final ExecutionException | InterruptedException e) {', '                }', '            });', '            thread.setName("stats-" + i);', '            threads.add(thread);', '            thread.start();', '        }', '        // release the hounds', '        barrier.await();', '        // wait for a failure, or for fifteen seconds to elapse', '        latch.await(15, TimeUnit.SECONDS);', '        // stop all threads and wait for them to complete', '        stop.set(true);', '        for (final Thread thread : threads) {', '            thread.join();', '        }', '        assertThat(shardFailures.get(), emptyCollectionOf(DefaultShardOperationFailedException.class));', '        assertThat(executionFailures.get(), emptyCollectionOf(Exception.class));'], 'add': ['import static org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits.MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE;', '        try {', '            updateClusterSettings(', '                Settings.builder().put(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey(), numberOfStatsThreads + 1)', '            );', '            for (int i = 0; i &lt; numberOfStatsThreads; i++) {', '                final Thread thread = new Thread(() -&gt; {', '                        barrier.await();', '                    } catch (final BrokenBarrierException | InterruptedException e) {', '                    final IndicesStatsRequest request = new IndicesStatsRequest();', '                    request.all();', '                    request.indices(new String[0]);', '                    while (stop.get() == false) {', '                        try {', '                            final IndicesStatsResponse response = client().admin().indices().stats(request).get();', '                            if (response.getFailedShards() &gt; 0) {', '                                failed.set(true);', '                                shardFailures.get().addAll(Arrays.asList(response.getShardFailures()));', '                                latch.countDown();', '                            }', '                        } catch (final ExecutionException | InterruptedException e) {', '                            failed.set(true);', '                            executionFailures.get().add(e);', '                            latch.countDown();', '                        }', '                    }', '                });', '                thread.setName("stats-" + i);', '                threads.add(thread);', '                thread.start();', '            }', '  // release the hounds', '  barrier.await();', '  // wait for a failure, or for fifteen seconds to elapse', '  latch.await(15, TimeUnit.SECONDS);', '  // stop all threads and wait for them to complete', '  stop.set(true);', '  for (final Thread thread : threads) {', '  thread.join();', '  }', '            assertThat(shardFailures.get(), emptyCollectionOf(DefaultShardOperationFailedException.class));', '            assertThat(executionFailures.get(), emptyCollectionOf(Exception.class));', '        } finally {', '            updateClusterSettings(Settings.builder().putNull(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey()));', '        }']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/40b56a42384ff6236fc0f2dccee220e30dac8a13', 'description': ['\n       Add issue to the change log\n    '], 'position': ['docs/changelog/83832.yaml'], 'code': {'cut': ['summary: Push back excessive requests for stats', 'issues: []'], 'add': ['summary: Push back excessive stats and recovery requests', 'issues:', '  - 51992']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/e6b5100bbb667dd3b3c02b382c03a25e173dfa44', 'description': ['\n       Update docs/changelog/83832.yaml\n    '], 'position': ['docs/changelog/83832.yaml'], 'code': {'cut': ['issues:', '  - 51992'], 'add': ['issues: []']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/d38e8194dde4da1bdb57fa1f58bc07847d1ac376', 'description': ['\n       Update docs/changelog/83832.yaml\n    '], 'position': ['docs/changelog/83832.yaml'], 'code': {'cut': ['issues: []'], 'add': ['issues:', ' - 51992']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/b917c57b7aacc53870c312c8269f8b6c3ce74836', 'description': ['\n       Revert format changes to docs\n    '], 'position': ['docs/reference/modules/cluster/misc.asciidoc'], 'code': {'cut': ['Shards for closed indices do not count toward this limit.Defaults to `1000`.', '{es} rejects any request that creates more shards than this limit allows.For', '(&lt;&lt;dynamic-cluster-setting,Dynamic&gt;&gt;) Limits the total number of primary and replica frozen shards for the cluster.', 'Shards for closed indices do not count toward this limit.Defaults to `3000`.', '`100` and three frozen data nodes has a frozen shard limit of 300. If the cluster already contains 296 shards, {es} rejects any request that adds five or more frozen shards to the cluster.', 'NOTE: These setting do not limit shards for individual nodes.', 'To limit the number of shards for each node, use the', '(&lt;&lt;dynamic-cluster-setting,Dynamic&gt;&gt;) Limits the bounded diagnostic requests a coordinating node can concurrently handle.', 'This can be used to store arbitrary, infrequently-changing data about the cluster without the need to create an index to store it.', 'This data may be stored using any key prefixed with `cluster.metadata.`.', 'For example, to store the email address of the administrator of a cluster under the key `cluster.metadata.administrator`, issue this request:', 'confidential information.Any information stored in user-defined cluster'], 'add': ['Shards for closed indices do not count toward this limit. Defaults to `1000`.', '{es} rejects any request that creates more shards than this limit allows. For', '(&lt;&lt;dynamic-cluster-setting,Dynamic&gt;&gt;)', 'Limits the total number of primary and replica frozen shards for the cluster.', 'Shards for closed indices do not count toward this limit. Defaults to `3000`.', '`100` and three frozen data nodes has a frozen shard limit of 300. If the', 'cluster already contains 296 shards, {es} rejects any request that adds five or', 'more frozen shards to the cluster.', 'NOTE: These setting do not limit shards for individual nodes. To limit the', 'number of shards for each node, use the', '(&lt;&lt;dynamic-cluster-setting,Dynamic&gt;&gt;)', 'Limits the bounded diagnostic requests a coordinating node can concurrently handle.', '', 'This can be used to store arbitrary, infrequently-changing data about the cluster', 'without the need to create an index to store it. This data may be stored using', 'any key prefixed with `cluster.metadata.`. For example, to store the email', 'address of the administrator of a cluster under the key `cluster.metadata.administrator`,', 'issue this request:', 'confidential information. Any information stored in user-defined cluster']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/f21a5173e079e53b07c90c67a136b7016ff44e6e', 'description': ['\n       First round of review\n    '], 'position': ['docs/reference/modules/cluster/misc.asciidoc', '...java/org/elasticsearch/action/support/broadcast/node/BoundedDiagnosticRequestPermits.java'], 'code': {'cut': ['Limits the bounded diagnostic requests a coordinating node can concurrently handle.', '    private volatile Integer maxConcurrentBoundedDiagnosticRequestsPerNode;', '        this.maxConcurrentBoundedDiagnosticRequestsPerNode = MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.get(settings);', ' this.maxConcurrentBoundedDiagnosticRequestsPerNode,', '        this.maxConcurrentBoundedDiagnosticRequestsPerNode = maxConcurrentBoundedDiagnosticRequestsPerNode;'], 'add': ['Limits the bounded diagnostic requests a coordinating node can concurrently handle. Defaults to `20`.', ' MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.get(settings),']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/35753a8dcc8bf19a067ee1dedbe2d415237f9987', 'description': ['\n       Refactor to enable extending the limiter usage\n    '], 'position': ['server/src/internalClusterTest/java/org/elasticsearch/indices/stats/IndexStatsIT.java', '...rc/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java', '...c/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java', 'server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java', '...java/org/elasticsearch/action/support/broadcast/node/BoundedDiagnosticRequestPermits.java', '...ava/org/elasticsearch/action/support/broadcast/node/TransportBoundedDiagnosticAction.java', 'server/src/main/java/org/elasticsearch/common/settings/ClusterSettings.java'], 'code': {'cut': ['import static org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits.MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE;', '            updateClusterSettings(', '                Settings.builder().put(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey(), numberOfStatsThreads + 1)', '            );', '            updateClusterSettings(Settings.builder().putNull(MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE.getKey()));', 'import org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits;', 'import org.elasticsearch.action.support.broadcast.node.TransportBoundedDiagnosticAction;', 'public class TransportRecoveryAction extends TransportBoundedDiagnosticAction&lt;RecoveryRequest, RecoveryResponse, RecoveryState&gt; {', ' BoundedDiagnosticRequestPermits boundedDiagnosticRequestPermits', '            ThreadPool.Names.MANAGEMENT,', '            boundedDiagnosticRequestPermits', 'import org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits;', 'import org.elasticsearch.action.support.broadcast.node.TransportBoundedDiagnosticAction;', 'public class TransportIndicesStatsAction extends TransportBoundedDiagnosticAction&lt;IndicesStatsRequest, IndicesStatsResponse, ShardStats&gt; {', ' BoundedDiagnosticRequestPermits boundedDiagnosticRequestPermits', '            ThreadPool.Names.MANAGEMENT,', '            boundedDiagnosticRequestPermits', 'import org.elasticsearch.action.support.broadcast.node.BoundedDiagnosticRequestPermits;', ' BoundedDiagnosticRequestPermits.MAX_CONCURRENT_BOUNDED_DIAGNOSTIC_REQUESTS_PER_NODE'], 'add': ['import static org.elasticsearch.action.support.StatsRequestLimiter.MAX_CONCURRENT_STATS_REQUESTS_PER_NODE;', '            updateClusterSettings(Settings.builder().put(MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.getKey(), numberOfStatsThreads + 1));', '            updateClusterSettings(Settings.builder().putNull(MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.getKey()));', 'import org.elasticsearch.action.support.StatsRequestLimiter;', 'import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;', 'public class TransportRecoveryAction extends TransportBroadcastByNodeAction&lt;RecoveryRequest, RecoveryResponse, RecoveryState&gt; {', '    private final StatsRequestLimiter statsRequestLimiter;', ' StatsRequestLimiter statsRequestLimiter', '            ThreadPool.Names.MANAGEMENT', '        this.statsRequestLimiter = statsRequestLimiter;', '    @Override', '    protected void doExecute(Task task, RecoveryRequest request, ActionListener&lt;RecoveryResponse&gt; listener) {', '        statsRequestLimiter.maybeDoExecute(task, request, listener, super::doExecute);', '    }', '', 'import org.elasticsearch.action.support.StatsRequestLimiter;', 'import org.elasticsearch.action.support.broadcast.node.TransportBroadcastByNodeAction;', 'public class TransportIndicesStatsAction extends TransportBroadcastByNodeAction&lt;IndicesStatsRequest, IndicesStatsResponse, ShardStats&gt; {', '    private final StatsRequestLimiter statsRequestLimiter;', ' StatsRequestLimiter statsRequestLimiter', '            ThreadPool.Names.MANAGEMENT', '        this.statsRequestLimiter = statsRequestLimiter;', '', '    @Override', '    protected void doExecute(Task task, IndicesStatsRequest request, ActionListener&lt;IndicesStatsResponse&gt; listener) {', '        statsRequestLimiter.maybeDoExecute(task, request, listener, super::doExecute);', '    }', '/*', ' * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one', ' * or more contributor license agreements. Licensed under the Elastic License', ' * 2.0 and the Server Side Public License, v 1; you may not use this file except', ' * in compliance with, at your election, the Elastic License 2.0 or the Server', ' * Side Public License, v 1.', ' */', '', 'package org.elasticsearch.action.support;', '', 'import org.elasticsearch.action.ActionListener;', 'import org.elasticsearch.common.TriConsumer;', 'import org.elasticsearch.common.settings.ClusterSettings;', 'import org.elasticsearch.common.settings.Setting;', 'import org.elasticsearch.common.settings.Settings;', 'import org.elasticsearch.common.util.concurrent.AdjustableSemaphore;', 'import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;', 'import org.elasticsearch.common.util.concurrent.RunOnce;', 'import org.elasticsearch.tasks.Task;', '', '/**', ' * This class guards the amount of stats requests a node can concurrently coordinate.', ' */', 'public class StatsRequestLimiter {', '', '    public static final Setting&lt;Integer&gt; MAX_CONCURRENT_STATS_REQUESTS_PER_NODE = Setting.intSetting(', '        "node.stats.max_concurrent_requests",', '        100,', '        1,', '        Setting.Property.NodeScope,', '        Setting.Property.Dynamic', '    );', '', '    private final AdjustableSemaphore maxConcurrentStatsRequestsPerNodeSemaphore;', '', '    public StatsRequestLimiter(Settings settings, ClusterSettings clusterSettings) {', '        this.maxConcurrentStatsRequestsPerNodeSemaphore = new AdjustableSemaphore(', '            MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.get(settings),', '            false', '        );', '        clusterSettings.addSettingsUpdateConsumer(MAX_CONCURRENT_STATS_REQUESTS_PER_NODE, this::setMaxConcurrentStatsRequestsPerNode);', '    }', '', '    private void setMaxConcurrentStatsRequestsPerNode(int maxConcurrentBoundedDiagnosticRequestsPerNode) {', '        this.maxConcurrentStatsRequestsPerNodeSemaphore.setMaxPermits(maxConcurrentBoundedDiagnosticRequestsPerNode);', '    }', '', '    public boolean tryAcquire() {', '        return maxConcurrentStatsRequestsPerNodeSemaphore.tryAcquire();', '    }', '', '    public void release() {', '        maxConcurrentStatsRequestsPerNodeSemaphore.release();', '    }', '', '    public &lt;Request, Response&gt; void maybeDoExecute(', '        Task task,', '        Request request,', '        ActionListener&lt;Response&gt; listener,', '        TriConsumer&lt;Task, Request, ActionListener&lt;Response&gt;&gt; execute', '    ) {', '        if (maxConcurrentStatsRequestsPerNodeSemaphore.tryAcquire()) {', '            final Runnable release = new RunOnce(maxConcurrentStatsRequestsPerNodeSemaphore::release);', '            boolean success = false;', '            try {', '                execute.apply(task, request, ActionListener.runBefore(listener, release::run));', '                success = true;', '            } finally {', '                if (success == false) {', '                    release.run();', '                }', '            }', '        } else {', '            listener.onFailure(new EsRejectedExecutionException("too many bounded diagnostic requests"));', '        }', '    }', '}', 'import org.elasticsearch.action.support.StatsRequestLimiter;', ' StatsRequestLimiter.MAX_CONCURRENT_STATS_REQUESTS_PER_NODE']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/cb317fd36e2f815e6a076fc2b76af4b7a3485b4f', 'description': ['\n       Adjust documentation\n    '], 'position': ['docs/reference/modules/cluster/misc.asciidoc'], 'code': {'cut': ['[[bounded-diagnostic-requests-limit]]', '===== Bounded diagnostic requests limit', 'A diagnostic request might require information from all nodes to be aggregated before it returns to the user.', 'These calls can be heavy and they put extra pressure on the coordinating node (the node collecting the responses from all the nodes), for this reason there is a limit on the concurrent requests that a node can coordinate.', 'Currently, the only bounded diagnostic requests are &lt;&lt;indices-stats, index stats&gt;&gt;', 'and &lt;&lt;indices-recovery, recovery&gt;&gt; APIs.', '[[cluster-max-concurrent-bounded-diagnostic-requests-per-node]]', '`cluster.max_concurrent_bounded_diagnostic_requests_per_node`::', 'Limits the bounded diagnostic requests a coordinating node can concurrently handle. Defaults to `20`.'], 'add': ['[[stats-requests-limit]]', '===== Stats request limit', 'A stats request might require information from all nodes to be aggregated before it returns to the user.', 'These requests can be heavy and they put extra pressure on the coordinating node (the node collecting the', 'responses from all the nodes), for this reason there is a limit on the concurrent requests that a node can coordinate.', '[[node-stats-max-concurrent-requests]]', '`node.stats.max_concurrent_requests`::', 'Limits the stats requests a coordinating node can concurrently handle. Defaults to `100`.']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/a1a31854f1dcfe6ff832ce3cf9490d0cd2ed59d6', 'description': ['\n       Improve testing of StatsRequestLimiter\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java', 'server/src/test/java/org/elasticsearch/action/support/StatsRequestLimiterTests.java'], 'code': {'cut': ['    public boolean tryAcquire() {', '        return maxConcurrentStatsRequestsPerNodeSemaphore.tryAcquire();', '    }', '', '    public void release() {', '        maxConcurrentStatsRequestsPerNodeSemaphore.release();', '    }', '', '    public void testGrantsPermitsUpToMaxPermits() {', '        int maxPermits = randomIntBetween(1, 5);', '            assertTrue(statsRequestLimiter.tryAcquire());', '        assertFalse(statsRequestLimiter.tryAcquire());', '        statsRequestLimiter.release();', '        assertTrue(statsRequestLimiter.tryAcquire());'], 'add': ['', '    // visible for testing', '    boolean tryAcquire() {', '        return maxConcurrentStatsRequestsPerNodeSemaphore.tryAcquire();', '    }', '', '    // visible for testting', '    void release() {', '        maxConcurrentStatsRequestsPerNodeSemaphore.release();', '    }', 'import org.elasticsearch.action.ActionListener;', 'import org.elasticsearch.common.TriConsumer;', 'import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;', 'import org.elasticsearch.tasks.Task;', 'import java.util.ArrayList;', 'import java.util.List;', 'import java.util.concurrent.BrokenBarrierException;', 'import java.util.concurrent.CyclicBarrier;', '', '    public void testGrantsPermitsUpToMaxPermits() throws Exception {', '        final int maxPermits = randomIntBetween(1, 5);', '        final List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(maxPermits);', '        final CyclicBarrier barrier = new CyclicBarrier(1 + maxPermits);', '        TriConsumer&lt;Task, Integer, ActionListener&lt;Integer&gt;&gt; execute = (task, i, actionListener) -&gt; {', '            final Thread thread = new Thread(() -&gt; {', '                try {', '                    barrier.await();', '                } catch (final BrokenBarrierException | InterruptedException e) {', '                    fail("Exception occurred while waiting for the barrier to be lifted");', '                }', '                actionListener.onResponse(i);', '            });', '            thread.setName("thread-" + i);', '            threads.add(thread);', '            thread.start();', '        };', '            PlainActionFuture&lt;Integer&gt; listener = new PlainActionFuture&lt;&gt;();', '            statsRequestLimiter.maybeDoExecute(null, i, listener, execute);', '        PlainActionFuture&lt;Integer&gt; listener = new PlainActionFuture&lt;&gt;();', '        statsRequestLimiter.maybeDoExecute(null, maxPermits, listener, execute);', '        expectThrows(EsRejectedExecutionException.class, listener::actionGet);', '', '        barrier.await();', '        for (Thread thread : threads) {', '            thread.join();', '        }', '        assertBusy(() -&gt; assertTrue(statsRequestLimiter.tryAcquire()));', '', '    public void testReleasingAfterException() {', '        ClusterSettings clusterSettings = new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);', '        StatsRequestLimiter statsRequestLimiter = new StatsRequestLimiter(', '            Settings.builder().put(MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.getKey(), 1).build(),', '            clusterSettings', '        );', '        PlainActionFuture&lt;Integer&gt; listener = new PlainActionFuture&lt;&gt;();', '        TriConsumer&lt;Task, Integer, ActionListener&lt;Integer&gt;&gt; execute = (task, input, actionListener) -&gt; {', '            // Verify that we hold the last permit', '            assertFalse(statsRequestLimiter.tryAcquire());', '            throw new RuntimeException("simulated");', '        };', '        expectThrows(RuntimeException.class, () -&gt; statsRequestLimiter.maybeDoExecute(null, 10, listener, execute));', '        assertTrue(statsRequestLimiter.tryAcquire());', '    }']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/d2c2264dd6b6c7adcb19baa46d623cdcf4921627', 'description': ["\n       Merge branch 'master' into push-back-excessive-requests-for-stats\n    "], 'position': ['server/src/main/java/org/elasticsearch/node/Node.java'], 'code': {'cut': ['            List&lt;HealthIndicatorService&gt; serverHealthIndicatorServices = List.of(', '                new InstanceHasMasterHealthIndicatorService(clusterService),', '                new RepositoryIntegrityHealthIndicatorService(clusterService)', '            );', '            List&lt;HealthIndicatorService&gt; pluginHealthIndicatorServices = pluginsService.filterPlugins(HealthPlugin.class)', '                .stream()', '                .flatMap(plugin -&gt; plugin.getHealthIndicatorServices().stream())', '                .toList();', '            HealthService healthService = new HealthService(concatLists(serverHealthIndicatorServices, pluginHealthIndicatorServices));'], 'add': ['', '            HealthService healthService = createHealthService(clusterService);']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/54609b301aac1a2b272a90e570eee158104f0764', 'description': ['\n       Add metrics for stats requests\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodeStats.java', '...er/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodesStatsRequest.java', '...ain/java/org/elasticsearch/action/admin/cluster/node/stats/TransportNodesStatsAction.java', '...c/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java', 'server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java', 'server/src/main/java/org/elasticsearch/action/support/StatsRequestStats.java', 'server/src/main/java/org/elasticsearch/node/Node.java'], 'code': {'cut': ['        @Nullable IndexingPressureStats indexingPressureStats', '        INDEXING_PRESSURE("indexing_pressure"),;', '            NodesStatsRequest.Metric.INDEXING_PRESSURE.containedIn(metrics)', '            final Runnable release = new RunOnce(maxConcurrentStatsRequestsPerNodeSemaphore::release);', '    // visible for testting', '                searchModule.getValuesSourceRegistry().getUsageService()', '', '            final StatsRequestLimiter statsRequestLimiter = new StatsRequestLimiter(settings, settingsModule.getClusterSettings());', ''], 'add': ['import org.elasticsearch.Version;', 'import org.elasticsearch.action.support.StatsRequestStats;', '    @Nullable', '    private StatsRequestStats statsRequestStats;', '', '        if (in.getVersion().onOrAfter(Version.V_8_2_0)) {', '            statsRequestStats = in.readOptionalWriteable(StatsRequestStats::new);', '        }', '        @Nullable IndexingPressureStats indexingPressureStats,', '        @Nullable StatsRequestStats statsRequestStats', '        this.statsRequestStats = statsRequestStats;', '    @Nullable', '    public StatsRequestStats getStatsRequestStats() {', '        return statsRequestStats;', '    }', '', '        if (out.getVersion().onOrAfter(Version.V_8_2_0)) {', '            out.writeOptionalWriteable(statsRequestStats);', '        }', '        if (getStatsRequestStats() != null) {', '            getStatsRequestStats().toXContent(builder, params);', '        }', '        INDEXING_PRESSURE("indexing_pressure"),', '        STATS_REQUESTS("stats_requests"),;', '            NodesStatsRequest.Metric.INDEXING_PRESSURE.containedIn(metrics),', '            NodesStatsRequest.Metric.STATS_REQUESTS.containedIn(metrics)', '            false,', 'import org.elasticsearch.common.metrics.CounterMetric;', 'import java.util.ArrayList;', 'import java.util.List;', 'import java.util.Map;', 'import java.util.concurrent.ConcurrentHashMap;', '', '    private final Map&lt;String, StatsHolder&gt; stats = new ConcurrentHashMap&lt;&gt;();', '        StatsHolder statsHolder = stats.computeIfAbsent(task.getAction(), ignored -&gt; new StatsHolder(task.getAction()));', '            statsHolder.current.inc();', '            final Runnable release = new RunOnce(() -&gt; {', '                maxConcurrentStatsRequestsPerNodeSemaphore.release();', '                statsHolder.current.dec();', '                statsHolder.completed.inc();', '            });', '            statsHolder.current.dec();', '            statsHolder.rejected.inc();', '        }', '    }', '', '    public StatsRequestStats stats() {', '        List&lt;StatsRequestStats.Stats&gt; statsPerAction = new ArrayList&lt;&gt;();', '        for (StatsHolder statsHolder : stats.values()) {', '            statsPerAction.add(statsHolder.stats());', '        return new StatsRequestStats(statsPerAction);', '    // visible for testing', '', '    static final class StatsHolder {', '        String request;', '        final CounterMetric current = new CounterMetric();', '        final CounterMetric completed = new CounterMetric();', '        final CounterMetric rejected = new CounterMetric();', '', '        StatsHolder(String request) {', '            this.request = request;', '        }', '', '        StatsRequestStats.Stats stats() {', '            return new StatsRequestStats.Stats(request, current.count(), completed.count(), rejected.count());', '        }', '    }', '/*', ' * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one', ' * or more contributor license agreements. Licensed under the Elastic License', ' * 2.0 and the Server Side Public License, v 1; you may not use this file except', ' * in compliance with, at your election, the Elastic License 2.0 or the Server', ' * Side Public License, v 1.', ' */', '', 'package org.elasticsearch.action.support;', '', 'import org.elasticsearch.common.io.stream.StreamInput;', 'import org.elasticsearch.common.io.stream.StreamOutput;', 'import org.elasticsearch.common.io.stream.Writeable;', 'import org.elasticsearch.xcontent.ToXContentFragment;', 'import org.elasticsearch.xcontent.XContentBuilder;', '', 'import java.io.IOException;', 'import java.util.Collections;', 'import java.util.Iterator;', 'import java.util.List;', '', 'public class StatsRequestStats implements Writeable, ToXContentFragment, Iterable&lt;StatsRequestStats.Stats&gt; {', '', '    public static class Stats implements Writeable, ToXContentFragment, Comparable&lt;Stats&gt; {', '', '        private final String request;', '        private final long current;', '        private final long completed;', '        private final long rejected;', '', '        public Stats(String request, long current, long completed, long rejected) {', '            this.request = request;', '            this.current = current;', '            this.completed = completed;', '            this.rejected = rejected;', '        }', '', '        public Stats(StreamInput in) throws IOException {', '            request = in.readString();', '            current = in.readLong();', '            completed = in.readLong();', '            rejected = in.readLong();', '        }', '', '        @Override', '        public void writeTo(StreamOutput out) throws IOException {', '            out.writeString(request);', '            out.writeLong(current);', '            out.writeLong(completed);', '            out.writeLong(rejected);', '        }', '', '        public String getRequest() {', '            return this.request;', '        }', '', '        public long getCurrent() {', '            return this.current;', '        }', '', '        public long getCompleted() {', '            return this.completed;', '        }', '', '        public long getRejected() {', '            return rejected;', '        }', '', '        @Override', '        public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {', '            builder.startObject(request);', '            if (current != -1) {', '                builder.field(Fields.CURRENT, current);', '            }', '            if (completed != -1) {', '                builder.field(Fields.COMPLETED, completed);', '            }', '            if (rejected != -1) {', '                builder.field(Fields.REJECTED, rejected);', '            }', '            builder.endObject();', '            return builder;', '        }', '', '        @Override', '        public int compareTo(Stats other) {', '            if ((getRequest() == null) &amp;&amp; (other.getRequest() == null)) {', '                return 0;', '            } else if ((getRequest() != null) &amp;&amp; (other.getRequest() == null)) {', '                return 1;', '            } else if (getRequest() == null) {', '                return -1;', '            } else {', '                int compare = getRequest().compareTo(other.getRequest());', '                if (compare == 0) {', '                    compare = Long.compare(getCompleted(), other.getCompleted());', '                }', '                return compare;', '            }', '        }', '    }', '', '    private List&lt;Stats&gt; stats;', '', '    public StatsRequestStats(List&lt;Stats&gt; stats) {', '        Collections.sort(stats);', '        this.stats = stats;', '    }', '', '    public StatsRequestStats(StreamInput in) throws IOException {', '        stats = in.readList(Stats::new);', '    }', '', '    @Override', '    public void writeTo(StreamOutput out) throws IOException {', '        out.writeList(stats);', '    }', '', '    @Override', '    public Iterator&lt;Stats&gt; iterator() {', '        return stats.iterator();', '    }', '', '    static final class Fields {', '        static final String CURRENT = "current";', '        static final String COMPLETED = "completed";', '        static final String REJECTED = "rejected";', '    }', '', '    @Override', '    public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {', '        builder.startObject("stats_requests");', '        for (Stats stat : stats) {', '            stat.toXContent(builder, params);', '        }', '        builder.endObject();', '        return builder;', '    }', '}', '            final StatsRequestLimiter statsRequestLimiter = new StatsRequestLimiter(settings, settingsModule.getClusterSettings());', '', '                searchModule.getValuesSourceRegistry().getUsageService(),', '                statsRequestLimiter']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/e9d9a2f6688b230917d5e2d914a0dd7d995af522', 'description': ['\n       Bug &amp; test fix\n    '], 'position': ['...rc/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java', '...c/main/java/org/elasticsearch/action/admin/indices/stats/TransportIndicesStatsAction.java', 'server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java', 'server/src/test/java/org/elasticsearch/action/support/StatsRequestLimiterTests.java'], 'code': {'cut': ['        statsRequestLimiter.maybeDoExecute(task, request, listener, super::doExecute);', '        statsRequestLimiter.maybeDoExecute(task, request, listener, super::doExecute);', '    public &lt;Request, Response&gt; void maybeDoExecute(', '            statsHolder.current.dec();', '        StatsRequestStats.Stats stats = statsRequestLimiter.stats().iterator().next();', '            statsRequestLimiter.maybeDoExecute(null, i, listener, execute);', '        statsRequestLimiter.maybeDoExecute(null, maxPermits, listener, execute);', '        expectThrows(RuntimeException.class, () -&gt; statsRequestLimiter.maybeDoExecute(null, 10, listener, execute));', '        StatsRequestStats.Stats stats = statsRequestLimiter.stats().iterator().next();'], 'add': ['        statsRequestLimiter.tryToExecute(task, request, listener, super::doExecute);', '        statsRequestLimiter.tryToExecute(task, request, listener, super::doExecute);', '    public &lt;Request, Response&gt; void tryToExecute(', 'import org.elasticsearch.tasks.TaskId;', 'import static java.util.Collections.emptyMap;', '', '            statsRequestLimiter.tryToExecute(createTask(), i, listener, execute);', '        statsRequestLimiter.tryToExecute(createTask(), maxPermits, listener, execute);', '        StatsRequestStats.Stats stats = getStats(statsRequestLimiter);', '        stats = getStats(statsRequestLimiter);', '        expectThrows(RuntimeException.class, () -&gt; statsRequestLimiter.tryToExecute(createTask(), 10, listener, execute));', '        StatsRequestStats.Stats stats = getStats(statsRequestLimiter);', '', '    private StatsRequestStats.Stats getStats(StatsRequestLimiter statsRequestLimiter) {', '        return statsRequestLimiter.stats().iterator().next();', '    }', '', '    private Task createTask() {', '        return new Task(', '            randomLong(),', '            "transport",', '            "stats_action",', '            "description",', '            new TaskId(randomLong() + ":" + randomLong()),', '            emptyMap()', '        );', '    }']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/801d4b2c7ad4bb55d8395090c6a7599cf491675d', 'description': ['\n       Update nodes stats reference documentation\n    '], 'position': ['docs/reference/cluster/nodes-stats.asciidoc'], 'code': {'cut': [], 'add': ['', '  `stats_requests`::', '      Statistics about stats requests such as indices stats, nodes stats,', '      recovery stats etc.', '======', '', '[[cluster-nodes-stats-api-response-body-stats-requests]]', '`stats_requests`::', '(object)', 'Contains statistics about the stats requests the node has received.', '+', '.Properties of `stats_requests`', '[%collapsible%open]', '======', '`&lt;stats_requests_name&gt;`::', '(object)', 'Contains statistics about a specific type of a stats request the node has received.', '+', '.Properties of `&lt;stats_requests_name&gt;`', '[%collapsible%open]', '=======', '`current`::', '(integer)', 'Number of stats requests currently in progress.', '', '`completed`::', '(integer)', 'Number of stats requests that have been completed by the node (successfully or', 'not).', '', '`rejected`::', '(integer)', 'Number of stats requests that were rejected by the node because it had reached', 'the limit of concurrent stats requests (`node.stats.max_concurrent_requests`).', '=======']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/404d10d0e996a5662ff7ef6e5aeeb238079e6454', 'description': ['\n       Limit other stats calls\n    '], 'position': ['.../main/java/org/elasticsearch/action/admin/cluster/node/info/TransportNodesInfoAction.java', '...ain/java/org/elasticsearch/action/admin/cluster/node/stats/TransportNodesStatsAction.java', '...ain/java/org/elasticsearch/action/admin/cluster/node/usage/TransportNodesUsageAction.java', '...c/main/java/org/elasticsearch/action/admin/cluster/stats/TransportClusterStatsAction.java', '.../java/org/elasticsearch/action/admin/indices/segments/TransportIndicesSegmentsAction.java'], 'code': {'cut': ['        ActionFilters actionFilters', '        ActionFilters actionFilters', '        AggregationUsageService aggregationUsageService', '        ActionFilters actionFilters', '        IndexNameExpressionResolver indexNameExpressionResolver'], 'add': ['import org.elasticsearch.action.ActionListener;', 'import org.elasticsearch.action.support.StatsRequestLimiter;', '    private final StatsRequestLimiter statsRequestLimiter;', '        ActionFilters actionFilters,', '        StatsRequestLimiter statsRequestLimiter', '        this.statsRequestLimiter = statsRequestLimiter;', '    @Override', '    protected void doExecute(Task task, NodesInfoRequest request, ActionListener&lt;NodesInfoResponse&gt; listener) {', '        statsRequestLimiter.tryToExecute(task, request, listener, super::doExecute);', '    }', '', 'import org.elasticsearch.action.ActionListener;', 'import org.elasticsearch.action.support.StatsRequestLimiter;', '    private final StatsRequestLimiter statsRequestLimiter;', '        ActionFilters actionFilters,', '        StatsRequestLimiter statsRequestLimiter', '        this.statsRequestLimiter = statsRequestLimiter;', '    @Override', '    protected void doExecute(Task task, NodesStatsRequest request, ActionListener&lt;NodesStatsResponse&gt; listener) {', '        statsRequestLimiter.tryToExecute(task, request, listener, super::doExecute);', '    }', '', 'import org.elasticsearch.action.ActionListener;', 'import org.elasticsearch.action.support.StatsRequestLimiter;', '    private final StatsRequestLimiter statsRequestLimiter;', '        AggregationUsageService aggregationUsageService,', '        StatsRequestLimiter statsRequestLimiter', '        this.statsRequestLimiter = statsRequestLimiter;', '    @Override', '    protected void doExecute(Task task, NodesUsageRequest request, ActionListener&lt;NodesUsageResponse&gt; listener) {', '        statsRequestLimiter.tryToExecute(task, request, listener, super::doExecute);', '    }', '', 'import org.elasticsearch.action.support.StatsRequestLimiter;', '    private final StatsRequestLimiter statsRequestLimiter;', '        ActionFilters actionFilters,', '        StatsRequestLimiter statsRequestLimiter', '        this.statsRequestLimiter = statsRequestLimiter;', '    @Override', '    protected void doExecute(Task task, ClusterStatsRequest request, ActionListener&lt;ClusterStatsResponse&gt; listener) {', '        statsRequestLimiter.tryToExecute(task, request, listener, super::doExecute);', '    }', '', 'import org.elasticsearch.action.support.StatsRequestLimiter;', '    private final StatsRequestLimiter statsRequestLimiter;', '        IndexNameExpressionResolver indexNameExpressionResolver,', '        StatsRequestLimiter statsRequestLimiter', '        this.statsRequestLimiter = statsRequestLimiter;', '', '    @Override', '    protected void doExecute(Task task, IndicesSegmentsRequest request, ActionListener&lt;IndicesSegmentResponse&gt; listener) {', '        statsRequestLimiter.tryToExecute(task, request, listener, super::doExecute);', '    }']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/348e457e8a37c07a734cfa6f7a48b1da46784689', 'description': ['\n       Fix changelog\n    '], 'position': ['docs/changelog/83832.yaml'], 'code': {'cut': ['summary: Push back excessive stats and recovery requests'], 'add': ['summary: Push back excessive stats requests']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/655743cc0b54864b16b3eb6f85d1cfcb6193b6b5', 'description': ['\n       Fix error message in StatsRequestLimiter\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java'], 'code': {'cut': ['            listener.onFailure(new EsRejectedExecutionException("too many bounded diagnostic requests"));'], 'add': ['            listener.onFailure(new EsRejectedExecutionException("too concurrent stats requests"));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/db06c8cf5441ae8f3f139f446c5b910848613df4', 'description': ['\n       Fix error message and javadoc(StatsRequestLimiter)\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java'], 'code': {'cut': ['        TriConsumer&lt;Task, Request, ActionListener&lt;Response&gt;&gt; execute', ' execute.apply(task, request, ActionListener.runBefore(listener, release::run));'], 'add': ['    /**', '     * Checks if executing the action will remain within the limits of the max concurrent requests the node can handle. If the limit is', '     * respected the action will be executed otherwise it will throw an EsRejectedExecutionException. The method keeps track of current,', '     * completed and rejected requests per action type.', '     */', '        TriConsumer&lt;Task, Request, ActionListener&lt;Response&gt;&gt; executeAction', ' executeAction.apply(task, request, ActionListener.runBefore(listener, release::run));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/61028ae14a17f0366e5f69416e608ff83e275da8', 'description': ['\n       Polishing\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java'], 'code': {'cut': ['        if (maxConcurrentStatsRequestsPerNodeSemaphore.tryAcquire()) {', ' maxConcurrentStatsRequestsPerNodeSemaphore.release();'], 'add': ['        if (tryAcquire()) {', '                release();']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/41c9a481aa067bcefb29a8f12b11ce9ce13337a4', 'description': ['\n       Use List.copyOf(..)\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java'], 'code': {'cut': ['        List&lt;StatsRequestStats.Stats&gt; statsPerAction = new ArrayList&lt;&gt;();', '        for (StatsHolder statsHolder : stats.values()) {', '            statsPerAction.add(statsHolder.stats());', '        }', '        return new StatsRequestStats(statsPerAction);'], 'add': ['        return new StatsRequestStats(List.copyOf(stats.values()));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/ed3f1ac63d3ac59ebbfbd4e9ad8704a84ae4225a', 'description': ['\n       Polishing\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java', '...csearch/action/support/broadcast/node/AbstractTransportBroadcastByNodeActionTestCase.java'], 'code': {'cut': ['import java.util.ArrayList;', 'import java.util.List;', '        this.maxConcurrentStatsRequestsPerNodeSemaphore = new AdjustableSemaphore(', '            MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.get(settings),', '            false', '        );', '    private void setMaxConcurrentStatsRequestsPerNode(int maxConcurrentBoundedDiagnosticRequestsPerNode) {', '        this.maxConcurrentStatsRequestsPerNodeSemaphore.setMaxPermits(maxConcurrentBoundedDiagnosticRequestsPerNode);', '            listener.onFailure(new EsRejectedExecutionException("too concurrent stats requests"));', '        return new StatsRequestStats(List.copyOf(stats.values()));'], 'add': ['import java.util.stream.Collectors;', '    private volatile int maxConcurrentStatsRequestsPerNode;', '        maxConcurrentStatsRequestsPerNode = MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.get(settings);', '        this.maxConcurrentStatsRequestsPerNodeSemaphore = new AdjustableSemaphore(maxConcurrentStatsRequestsPerNode, false);', '    private void setMaxConcurrentStatsRequestsPerNode(int maxConcurrentStatsRequestsPerNode) {', '        this.maxConcurrentStatsRequestsPerNode = maxConcurrentStatsRequestsPerNode;', '        this.maxConcurrentStatsRequestsPerNodeSemaphore.setMaxPermits(maxConcurrentStatsRequestsPerNode);', '            listener.onFailure(', '                new EsRejectedExecutionException("too concurrent stats requests (limit: " + maxConcurrentStatsRequestsPerNode + ")")', '            );', '        return new StatsRequestStats(stats.values().stream().map(StatsHolder::stats).collect(Collectors.toList()));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/83832/commits/5a8ae08cf1e80461cd521e9052707a4bb5537c6d', 'description': ['\n       Improve error message\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/StatsRequestLimiter.java', 'server/src/test/java/org/elasticsearch/action/support/StatsRequestLimiterTests.java'], 'code': {'cut': ['                new EsRejectedExecutionException("too concurrent stats requests (limit: " + maxConcurrentStatsRequestsPerNode + ")")', '        StatsRequestLimiter statsRequestLimiter = new StatsRequestLimiter(', '            Settings.builder().put(MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.getKey(), maxPermits).build(),', '            clusterSettings', '        );', '        expectThrows(EsRejectedExecutionException.class, listener::actionGet);'], 'add': ['                new EsRejectedExecutionException(', '                    "this node is already coordinating ["', '                        + maxConcurrentStatsRequestsPerNode', '                        + "] stats requests and has reached the limit set by ["', '                        + MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.getKey()', '                        + "]"', '                )', '        Settings settings = Settings.builder().put(MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.getKey(), maxPermits).build();', '        StatsRequestLimiter statsRequestLimiter = new StatsRequestLimiter(settings, clusterSettings);', '        String expectedExceptionMessage = "this node is already coordinating ["', '            + MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.get(settings)', '            + "] stats requests and has reached the limit set by ["', '            + MAX_CONCURRENT_STATS_REQUESTS_PER_NODE.getKey()', '            + "]";', '        expectThrows(EsRejectedExecutionException.class, expectedExceptionMessage, listener::actionGet);']}}], 'title': 'Push back excessive requests for stats'}
        , {'origin_url': 'https://github.com/elastic/elasticsearch/pull/83189', 'comment': [' Reduce the maximum number of generated dimensions in order to prevent the test from OOMing until we have a more robust mechanism of handling high-cardinality fields. Closes #83187 '], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/83189/commits/d9dbbbe40c612288413aca08dfea638b90d8571e', 'description': ['\n       Fix OOM in TimeSeriesAggregationsIT tests\n    '], 'position': ['...ernalClusterTest/java/org/elasticsearch/search/aggregations/TimeSeriesAggregationsIT.java'], 'code': {'cut': ['            dimensions[i] = randomUnique(() -&gt; randomAlphaOfLength(10), randomIntBetween(1, 30 / numberOfMetrics)).toArray(new String[0]);'], 'add': ['            dimensions[i] = randomUnique(() -&gt; randomAlphaOfLength(10), randomIntBetween(1, 20 / numberOfDimensions)).toArray(', '                new String[0]', '            );']}}], 'title': 'Fix OOM in TimeSeriesAggregationsIT tests'}
        , {'origin_url': 'https://github.com/elastic/elasticsearch/pull/82793', 'comment': [" These tests cover a bunch of failure cases which means they generate a lot of logs by design, but the logs are kind of useless: the tests are deterministic so we can reproduce any failures locally, and typically the default logs aren't enough for debugging anyway. Moreover if enough of these tests fail then we can apparently get Gradle to OOM which is much harder to debug. With this commit we turn the log verbosity down on these tests down as far as possible. "], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/82793/commits/db9e31e196438ed0ff5723485dd3e62e53d2ae3a', 'description': ['\n       Suppress most logs in CoordinatorTests\n    '], 'position': ['server/src/test/java/org/elasticsearch/cluster/coordination/CoordinatorTests.java'], 'code': {'cut': ['    @TestLogging(reason = "testing debug logging of LagDetector", value = "org.elasticsearch.cluster.coordination.LagDetector:DEBUG")'], 'add': ['@TestLogging(reason = "these tests do a lot of log-worthy things but we usually don\'t care", value = "org.elasticsearch:FATAL")', '    @TestLogging(', '        reason = "test includes assertions about Coordinator and JoinHelper logging",', '        value = "org.elasticsearch.cluster.coordination.Coordinator:WARN,org.elasticsearch.cluster.coordination.JoinHelper:INFO"', '    )', '    @TestLogging(', '        reason = "test includes assertions about JoinHelper logging",', '        value = "org.elasticsearch.cluster.coordination.JoinHelper:INFO"', '    )', '    @TestLogging(', '        reason = "testing ClusterFormationFailureHelper logging",', '        value = "org.elasticsearch.cluster.coordination.ClusterFormationFailureHelper:WARN"', '    )', '    @TestLogging(', '        reason = "testing LagDetector and CoordinatorPublication logging",', '        value = "org.elasticsearch.cluster.coordination.LagDetector:DEBUG,"', '            + "org.elasticsearch.cluster.coordination.Coordinator.CoordinatorPublication:INFO"', '    )']}}], 'title': 'Suppress most logs in CoordinatorTests'}
        , {'origin_url': 'https://github.com/elastic/elasticsearch/pull/82685', 'comment': [' Discard intermediate results when a stats request is cancelled. Next tasks:   Discuss approach  Improve understanding of _cluster/state request  Check completeness, did we cover all the endpoints that cause problems  Implement tests  Pass tests  Resolves #82337 ', ' This generally looks good to me, I left an optional comment ', ' Looks good @gmarouli, I left a handful of small comments. '], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/bc9bc00eb60dfb46c22edb1a399ceeb9ff77aa29', 'description': ['\n       CancellableTask can notify registered listeners\n    '], 'position': ['server/src/main/java/org/elasticsearch/tasks/CancellableTask.java', '...rc/test/java/org/elasticsearch/action/admin/cluster/node/tasks/CancellableTasksTests.java'], 'code': {'cut': ['            new ActionListener&lt;NodesResponse&gt;() {'], 'add': ['import java.util.concurrent.ConcurrentLinkedQueue;', '    private final ConcurrentLinkedQueue&lt;CancellationListener&gt; listeners = new ConcurrentLinkedQueue&lt;&gt;();', '            listeners.forEach(CancellationListener::onCancelled);', '    /**', '     * This method registers a listener that needs to be notified when this task is cancelled given that the task is not cancelled yet.', '     */', '    public final boolean registerListener(CancellationListener listener) {', '        if (isCancelled) {', '            return false;', '        }', '        return listeners.add(listener);', '    }', '', '', '    /**', '     * This interface is implemented by any class that needs to react to the cancellation of this task.', '     */', '    public interface CancellationListener {', '        void onCancelled();', '    }', '        AtomicBoolean listenerCalledUponCancellation = new AtomicBoolean(false);', '            new ActionListener&lt;&gt;() {', '        assert mainTask instanceof CancellableTask;', '        assertTrue(((CancellableTask) mainTask).registerListener(() -&gt; listenerCalledUponCancellation.set(true)));', '', '            // Verify the registered listeners have been notified', '            assertTrue(listenerCalledUponCancellation.get());', '            // Verify that a cancellation listener cannot be added to an already cancelled task', '            assertFalse(((CancellableTask) mainTask).registerListener(() -&gt; {}));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/81f88a2e5cc311c20aeaf9d50f8bcf8337513d39', 'description': ['\n       Test case to show the bug\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java', 'server/src/test/java/org/elasticsearch/action/support/nodes/TransportNodesActionTests.java'], 'code': {'cut': [], 'add': ['        // For testing purposes', '        AtomicReferenceArray&lt;Object&gt; getResponses() {', '            return responses;', '        }', '', '    public void testDiscardingResultUponCancellation() {', '        TransportNodesAction&lt;TestNodesRequest, TestNodesResponse, TestNodeRequest, TestNodeResponse&gt; action = getTestTransportNodesAction();', '        List&lt;String&gt; nodeIds = new ArrayList&lt;&gt;();', '        for (DiscoveryNode node : clusterService.state().nodes()) {', '            nodeIds.add(node.getId());', '        }', '', '        TestNodesRequest request = new TestNodesRequest(nodeIds.toArray(new String[0]));', '        PlainActionFuture&lt;TestNodesResponse&gt; listener = new PlainActionFuture&lt;&gt;();', '        CancellableTask cancellableTask = new CancellableTask(randomLong(), "transport", "action", "", null, emptyMap());', '        TransportNodesAction&lt;TestNodesRequest, TestNodesResponse, TestNodeRequest, TestNodeResponse&gt;.AsyncAction asyncAction =', '            action.new AsyncAction(cancellableTask, request, listener);', '        asyncAction.start();', '        Map&lt;String, List&lt;CapturingTransport.CapturedRequest&gt;&gt; capturedRequests = transport.getCapturedRequestsByTargetNodeAndClear();', '        for (List&lt;CapturingTransport.CapturedRequest&gt; requests : capturedRequests.values()) {', '            for (CapturingTransport.CapturedRequest capturedRequest : requests) {', '                transport.handleResponse(capturedRequest.requestId, new TestNodeResponse(capturedRequest.node));', '            }', '        }', '        TaskCancelHelper.cancel(cancellableTask, "simulated");', '        AtomicReferenceArray&lt;Object&gt; responses = asyncAction.getResponses();', '        for (int i = 0; i &lt; responses.length(); i++) {', '            assertNull(responses.get(i));', '        }', '        assertTrue(listener.isDone());', '    }', '']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/0243f24cd365af8e9e260ed3891d4e9ab0ba59c1', 'description': ['\n       Discard intermediate results upon cancellation\n    '], 'position': ['.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java', 'server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java'], 'code': {'cut': ['    protected class AsyncAction {', '            if (task instanceof CancellableTask &amp;&amp; ((CancellableTask) task).notifyIfCancelled(listener)) {', '    class AsyncAction {', '            responses.set(idx, nodeResponse);', '            logger.debug(new ParameterizedMessage("failed to execute on node [{}]", nodeId), t);', '            responses.set(idx, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t));', '            if (task instanceof CancellableTask &amp;&amp; ((CancellableTask) task).notifyIfCancelled(listener)) {'], 'add': ['    protected class AsyncAction implements CancellableTask.CancellationListener {', '        private volatile boolean cancelled = false;', '            if (task instanceof CancellableTask cancellableTask) {', '                if (cancellableTask.registerListener(this) == false) {', '                    cancellableTask.notifyIfCancelled(listener);', '                    return;', '                }', '            }', '            if (cancelled) {', '                return;', '            }', '', '            if (cancelled) {', '                return;', '            }', '', '            if (cancelled) {', '', '        @Override', '        public void onCancelled() {', '            cancelled = (task instanceof CancellableTask t) &amp;&amp; t.notifyIfCancelled(listener);', '            for (int i = 0; i &lt; responses.length(); i++) {', '                responses.set(i, null);', '            }', '        }', '    class AsyncAction implements CancellableTask.CancellationListener {', '        private volatile boolean cancelled = false;', '            if (task instanceof CancellableTask cancellableTask) {', '                if (cancellableTask.registerListener(this) == false) {', '                    cancellableTask.notifyIfCancelled(listener);', '                    return;', '                }', '            }', '            if (cancelled == false) {', '                responses.set(idx, nodeResponse);', '            }', '            if (cancelled == false) {', '                logger.debug(new ParameterizedMessage("failed to execute on node [{}]", nodeId), t);', '                responses.set(idx, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t));', '            }', '            if (cancelled) {', '', '        @Override', '        public void onCancelled() {', '            cancelled = (task instanceof CancellableTask t) &amp;&amp; t.notifyIfCancelled(listener);', '            for (int i = 0; i &lt; responses.length(); i++) {', '                responses.set(i, null);', '            }', '        }']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/4eec5faff46b56d3370602e8b1c72887c9744934', 'description': ['\n       Fix format\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java', '...rc/test/java/org/elasticsearch/action/admin/cluster/node/tasks/CancellableTasksTests.java'], 'code': {'cut': ['            if (cancelled == false) {', ' responses.set(idx, nodeResponse);', '            if (cancelled == false) {', '                logger.debug(new ParameterizedMessage("failed to execute on node [{}]", nodeId), t);', '                responses.set(idx, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t));', '        Task mainTask = startCancellableTestNodesAction(', '            waitForActionToStart,', '            runNodesCount,', '            blockedNodesCount,', '            new ActionListener&lt;&gt;() {', '                @Override', '                public void onResponse(NodesResponse listTasksResponse) {', '                    responseReference.set(listTasksResponse);', '                    responseLatch.countDown();', '                }', '                @Override', '                public void onFailure(Exception e) {', '                    throwableReference.set(e);', '                    responseLatch.countDown();', '                }', '        );'], 'add': ['            if (cancelled) {', ' return;', '', '            responses.set(idx, nodeResponse);', '            if (cancelled) {', '                return;', '', '            logger.debug(new ParameterizedMessage("failed to execute on node [{}]", nodeId), t);', '            responses.set(idx, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t));', '        Task mainTask = startCancellableTestNodesAction(waitForActionToStart, runNodesCount, blockedNodesCount, new ActionListener&lt;&gt;() {', '            @Override', '            public void onResponse(NodesResponse listTasksResponse) {', '                responseReference.set(listTasksResponse);', '                responseLatch.countDown();', '            }', '            @Override', '            public void onFailure(Exception e) {', '                throwableReference.set(e);', '                responseLatch.countDown();', ' });']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/c18eaad138eb4fe4889f4574636d8bed87b81feb', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/30666bac5ac98a29d1af71d052b99718a63e4ae8', 'description': ['\n       Fix test\n    '], 'position': ['server/src/test/java/org/elasticsearch/action/support/nodes/TransportNodesActionTests.java'], 'code': {'cut': ['    public void testTaskCancellationThrowsException() {', '        TaskCancelHelper.cancel(cancellableTask, "simulated");', '        action.doExecute(cancellableTask, request, listener);', '        expectThrows(ExecutionException.class, TaskCancelledException.class, listener::get);', '    }', '', '    public void testDiscardingResultUponCancellation() {', '        TransportNodesAction&lt;TestNodesRequest, TestNodesResponse, TestNodeRequest, TestNodeResponse&gt; action = getTestTransportNodesAction();', '        List&lt;String&gt; nodeIds = new ArrayList&lt;&gt;();', '        for (DiscoveryNode node : clusterService.state().nodes()) {', '            nodeIds.add(node.getId());', '        }', '', '        TestNodesRequest request = new TestNodesRequest(nodeIds.toArray(new String[0]));', '        PlainActionFuture&lt;TestNodesResponse&gt; listener = new PlainActionFuture&lt;&gt;();', '        CancellableTask cancellableTask = new CancellableTask(randomLong(), "transport", "action", "", null, emptyMap());', '        TransportNodesAction&lt;TestNodesRequest, TestNodesResponse, TestNodeRequest, TestNodeResponse&gt;.AsyncAction asyncAction =', '            action.new AsyncAction(cancellableTask, request, listener);', '        asyncAction.start();', '        Map&lt;String, List&lt;CapturingTransport.CapturedRequest&gt;&gt; capturedRequests = transport.getCapturedRequestsByTargetNodeAndClear();', '        for (List&lt;CapturingTransport.CapturedRequest&gt; requests : capturedRequests.values()) {', '            for (CapturingTransport.CapturedRequest capturedRequest : requests) {', '                transport.handleResponse(capturedRequest.requestId, new TestNodeResponse(capturedRequest.node));', '            }', '        TaskCancelHelper.cancel(cancellableTask, "simulated");', '        AtomicReferenceArray&lt;Object&gt; responses = asyncAction.getResponses();', '        for (int i = 0; i &lt; responses.length(); i++) {', '            assertNull(responses.get(i));', '        }', '        assertTrue(listener.isDone());'], 'add': ['    public void testTaskCancellation() {', '        TransportNodesAction&lt;TestNodesRequest, TestNodesResponse, TestNodeRequest, TestNodeResponse&gt;.AsyncAction asyncAction =', '            action.new AsyncAction(cancellableTask, request, listener);', '        asyncAction.start();', '        int cancelAt = randomIntBetween(1, capturedRequests.values().size() - 2);', '        int requestCount = 0;', '            if (requestCount == cancelAt) {', '                TaskCancelHelper.cancel(cancellableTask, "simulated");', '            }', '            requestCount++;', '        for (int i = 0; i &lt; asyncAction.getResponses().length(); i++) {', '            assertNull(asyncAction.getResponses().get(i));', '        expectThrows(ExecutionException.class, TaskCancelledException.class, listener::get);']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/e8dd984920fb34201aa601fb56a63f4402bca2c6', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/b1e833b5a5ec0c34fb8f99df9f29fd216de57057', 'description': ['\n       Introduce intermediate node response collector\n    '], 'position': ['...c/internalClusterTest/java/org/elasticsearch/action/admin/cluster/node/tasks/TasksIT.java', 'server/src/main/java/org/elasticsearch/action/support/IntermediateNodeResponses.java', '.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java'], 'code': {'cut': ['        assertEquals(', '            0,', '            client().admin().cluster().prepareListTasks().setActions(TestTaskPlugin.TestTaskAction.NAME + "*").get().getTasks().size()', 'import java.util.concurrent.atomic.AtomicReferenceArray;', ' AtomicReferenceArray&lt;?&gt; responses,', '        for (int i = 0; i &lt; responses.length(); i++) {', '            if (responses.get(i)instanceof FailedNodeException exception) {', '                totalShards += nodes.get(exception.nodeId()).size();', '                for (ShardRouting shard : nodes.get(exception.nodeId())) {', '                    exceptions.add(new DefaultShardOperationFailedException(shard.getIndexName(), shard.getId(), exception));', '                }', '            } else {', '                @SuppressWarnings("unchecked")', '                NodeResponse response = (NodeResponse) responses.get(i);', '                broadcastByNodeResponses.addAll(response.results);', '                totalShards += response.getTotalShards();', '                successfulShards += response.getSuccessfulShards();', '                for (BroadcastShardOperationFailedException throwable : response.getExceptions()) {', '                    if (TransportActions.isShardNotAvailableException(throwable) == false) {', '                        exceptions.add(', '                            new DefaultShardOperationFailedException(', '                                throwable.getShardId().getIndexName(),', '                                throwable.getShardId().getId(),', '                                throwable', '                            )', '                        );', '        totalShards += unavailableShardCount;', '        int failedShards = exceptions.size();', '        return newResponse(request, totalShards, successfulShards, failedShards, broadcastByNodeResponses, exceptions, clusterState);', '        private final AtomicReferenceArray&lt;Object&gt; responses;', '        private final AtomicInteger counter = new AtomicInteger();', '        private volatile boolean cancelled = false;', ' responses = new AtomicReferenceArray&lt;&gt;(nodeIds.size());', '            if (cancelled) {', '                return;', '            }', '', '            // this is defensive to protect against the possibility of double invocation', '            // the current implementation of TransportService#sendRequest guards against this', '            // but concurrency is hard, safety is important, and the small performance loss here does not matter', '            if (responses.compareAndSet(nodeIndex, null, response)) {', '                if (counter.incrementAndGet() == responses.length()) {', '                    onCompletion();', '                }', '            if (cancelled) {', '                return;', '            }', '', '            // this is defensive to protect against the possibility of double invocation', '            // the current implementation of TransportService#sendRequest guards against this', '            // but concurrency is hard, safety is important, and the small performance loss here does not matter', '            if (responses.compareAndSet(nodeIndex, null, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t))) {', '                if (counter.incrementAndGet() == responses.length()) {', '                    onCompletion();', '                }', '            if (cancelled) {', '                return;', '            }', '', '                response = newResponse(request, responses, unavailableShardCount, nodeIds, clusterState);', '            if (response != null) {', '            cancelled = (task instanceof CancellableTask t) &amp;&amp; t.notifyIfCancelled(listener);', '            for (int i = 0; i &lt; responses.length(); i++) {', '                responses.set(i, null);'], 'add': ['        assertBusy(', '            () -&gt; assertEquals(', '                0,', '                client().admin().cluster().prepareListTasks().setActions(TestTaskPlugin.TestTaskAction.NAME + "*").get().getTasks().size()', '            ),', '            2,', '            TimeUnit.SECONDS', '/*', ' * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one', ' * or more contributor license agreements. Licensed under the Elastic License', ' * 2.0 and the Server Side Public License, v 1; you may not use this file except', ' * in compliance with, at your election, the Elastic License 2.0 or the Server', ' * Side Public License, v 1.', ' */', '', 'package org.elasticsearch.action.support;', '', 'import java.util.Collection;', 'import java.util.concurrent.atomic.AtomicInteger;', 'import java.util.concurrent.atomic.AtomicReferenceArray;', '', '/**', ' * This class collects and tracks the intermediate responses that can be used to construct the aggregation response. It also gives the', ' * possibility to discard the intermediate results when asked, a use case for this call is when a task is cancelled.', ' */', 'public class IntermediateNodeResponses {', '    private final int expectedResponses;', '    private final AtomicInteger counter = new AtomicInteger();', '    private volatile AtomicReferenceArray&lt;Object&gt; responses;', '    private volatile boolean discarded = false;', '', '    public IntermediateNodeResponses(int size) {', '        this.expectedResponses = size;', '        this.responses = new AtomicReferenceArray&lt;&gt;(size);', '    }', '', '    public IntermediateNodeResponses(Collection&lt;Object&gt; array) {', '        this.responses = new AtomicReferenceArray&lt;&gt;(array.toArray());', '        this.expectedResponses = responses.length();', '    }', '', '    /**', '     * This method marks the responses as discarded and actually discards the results collected so far', '     */', '    public void discard() {', '        if (discarded == false) {', '            discarded = true;', '            responses = null;', '        }', '    }', '', '    public boolean isComplete() {', '        return discarded == false &amp;&amp; expectedResponses == counter.get();', '    }', '', '    public boolean isDiscarded() {', '        return discarded;', '    }', '', '    /**', "     * This method stores a new node response if it is first response encountered from this node and the intermediate responses haven't", '     * been discarded yet. Checking that this is the first time we have received a response from this node is a defensive mechanism to', '     * protect against the possibility of double invocation.', '     * @param nodeIndex, the index that represents a single node of the cluster', '     * @param response, a response can be either a NodeResponse or an error', '     * @return true if it was successfully stored, else false', '     */', '    public boolean maybeAddResponse(int nodeIndex, Object response) {', '        AtomicReferenceArray&lt;Object&gt; responses = this.responses;', '        if (discarded) {', '            return false;', '        }', '        if (responses.compareAndSet(nodeIndex, null, response)) {', '            counter.incrementAndGet();', '            return true;', '        } else {', '            return false;', '        }', '    }', '', '    public Object getResponse(int nodeIndex) throws AlreadyDiscardedException {', '        AtomicReferenceArray&lt;Object&gt; responses = this.responses;', '        if (discarded) {', '            throw new AlreadyDiscardedException();', '        }', '        return responses.get(nodeIndex);', '    }', '', '    public int size() throws AlreadyDiscardedException {', '        if (discarded) {', '            throw new AlreadyDiscardedException();', '        }', '        return expectedResponses;', '    }', '', '    public static class AlreadyDiscardedException extends Exception {}', '}', 'import org.elasticsearch.action.support.IntermediateNodeResponses;', ' IntermediateNodeResponses responseCollector,', '        try {', '            for (int i = 0; i &lt; responseCollector.size(); i++) {', '                Object response = responseCollector.getResponse(i);', '                if (response instanceof FailedNodeException exception) {', '                    totalShards += nodes.get(exception.nodeId()).size();', '                    for (ShardRouting shard : nodes.get(exception.nodeId())) {', '                        exceptions.add(new DefaultShardOperationFailedException(shard.getIndexName(), shard.getId(), exception));', '                    }', '                } else {', '                    @SuppressWarnings("unchecked")', '                    NodeResponse nodeResponse = (NodeResponse) response;', '                    broadcastByNodeResponses.addAll(nodeResponse.results);', '                    totalShards += nodeResponse.getTotalShards();', '                    successfulShards += nodeResponse.getSuccessfulShards();', '                    for (BroadcastShardOperationFailedException throwable : nodeResponse.getExceptions()) {', '                        if (TransportActions.isShardNotAvailableException(throwable) == false) {', '                            exceptions.add(', '                                new DefaultShardOperationFailedException(', '                                    throwable.getShardId().getIndexName(),', '                                    throwable.getShardId().getId(),', '                                    throwable', '                                )', '                            );', '                        }', '            totalShards += unavailableShardCount;', '            int failedShards = exceptions.size();', '            return newResponse(request, totalShards, successfulShards, failedShards, broadcastByNodeResponses, exceptions, clusterState);', '        } catch (IntermediateNodeResponses.AlreadyDiscardedException exception) {', '            return null;', '        private final IntermediateNodeResponses responseCollector;', ' responseCollector = new IntermediateNodeResponses(nodeIds.size());', '                    responseCollector.discard();', '            if (responseCollector.maybeAddResponse(nodeIndex, response) &amp;&amp; responseCollector.isComplete()) {', '                onCompletion();', '            if (responseCollector.maybeAddResponse(nodeIndex, t) &amp;&amp; responseCollector.isComplete()) {', '                onCompletion();', '                response = newResponse(request, responseCollector, unavailableShardCount, nodeIds, clusterState);', '            if (responseCollector.isComplete() &amp;&amp; response != null) {', '            if ((task instanceof CancellableTask t) &amp;&amp; t.notifyIfCancelled(listener)) {', '                responseCollector.discard();']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/21460c6fa4ac75de32d90e9d254775e59ba3ea30', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/89230a47da250585b4080aefa9ad21a660d1ae7e', 'description': ['\n       Test IntermediateNodeResponses\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/IntermediateNodeResponses.java', 'server/src/test/java/org/elasticsearch/action/support/IntermediateNodeResponsesTests.java'], 'code': {'cut': [' * This class collects and tracks the intermediate responses that can be used to construct the aggregation response. It also gives the', '     * This method marks the responses as discarded and actually discards the results collected so far', '            throw new AlreadyDiscardedException();', '            throw new AlreadyDiscardedException();'], 'add': [' * This class collects and tracks the intermediate responses that can be used to construct the aggregated response. It also gives the', '', '    private static final AlreadyDiscardedException ALREADY_DISCARDED_EXCEPTION = new AlreadyDiscardedException();', '', '     * This method marks the responses as discarded and discards the results collected to free up the resources', '            throw ALREADY_DISCARDED_EXCEPTION;', '            throw ALREADY_DISCARDED_EXCEPTION;', '/*', ' * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one', ' * or more contributor license agreements. Licensed under the Elastic License', ' * 2.0 and the Server Side Public License, v 1; you may not use this file except', ' * in compliance with, at your election, the Elastic License 2.0 or the Server', ' * Side Public License, v 1.', ' */', '', 'package org.elasticsearch.action.support;', '', 'import org.elasticsearch.test.ESTestCase;', '', 'public class IntermediateNodeResponsesTests extends ESTestCase {', '', '    public void testCompletion() throws Exception {', '        int size = randomIntBetween(1, 10);', '        IntermediateNodeResponses intermediateNodeResponses = new IntermediateNodeResponses(size);', '        for (int i = 0; i &lt; size; i++) {', '            assertTrue(intermediateNodeResponses.maybeAddResponse(i, randomBoolean() ? i : new Exception("from node " + i)));', '        }', '', '        assertTrue(intermediateNodeResponses.isComplete());', '        assertFalse(intermediateNodeResponses.isDiscarded());', '        assertEquals(size, intermediateNodeResponses.size());', '        for (int i = 0; i &lt; size; i++) {', '            assertNotNull(intermediateNodeResponses.getResponse(i));', '            if (intermediateNodeResponses.getResponse(i)instanceof Integer nodeResponse) {', '                assertEquals(i, nodeResponse.intValue());', '            }', '        }', '    }', '', '    public void testCancellation() {', '        int size = randomIntBetween(2, 10);', '        int cancelAt = randomIntBetween(0, size - 2);', '        IntermediateNodeResponses intermediateNodeResponses = new IntermediateNodeResponses(size);', '        for (int i = 0; i &lt; size; i++) {', '            if (i == cancelAt) {', '                intermediateNodeResponses.discard();', '            }', '            boolean added = intermediateNodeResponses.maybeAddResponse(i, randomBoolean() ? i : new Exception("from node " + i));', '            if (i &lt; cancelAt) {', '                assertTrue(added);', '            } else {', '                assertFalse(added);', '            }', '        }', '', '        assertTrue(intermediateNodeResponses.isDiscarded());', '        assertFalse(intermediateNodeResponses.isComplete());', '        expectThrows(IntermediateNodeResponses.AlreadyDiscardedException.class, intermediateNodeResponses::size);', '        expectThrows(IntermediateNodeResponses.AlreadyDiscardedException.class, () -&gt; intermediateNodeResponses.getResponse(0));', '    }', '', '    public void testResponseIsRegistredOnlyOnce() throws Exception {', '        IntermediateNodeResponses intermediateNodeResponses = new IntermediateNodeResponses(1);', '        assertTrue(intermediateNodeResponses.maybeAddResponse(0, "response1"));', '        assertFalse(intermediateNodeResponses.maybeAddResponse(0, "response2"));', '        assertEquals("response1", intermediateNodeResponses.getResponse(0));', '    }', '}']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/583dc06053f2adc11bae68f5f671b60b30ad4d6c', 'description': ['\n       Fix deadlock\n    '], 'position': ['server/src/main/java/org/elasticsearch/tasks/CancellableTask.java'], 'code': {'cut': ['            listeners.forEach(CancellationListener::onCancelled);'], 'add': ['        listeners.forEach(CancellationListener::onCancelled);']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/78e0292430f8e9c16bbe9f9596ad663e054f34a5', 'description': ['\n       Fix prematurely closing the listener\n    '], 'position': ['...c/internalClusterTest/java/org/elasticsearch/action/admin/cluster/node/tasks/TasksIT.java', '...on/support/IntermediateNodeResponses.java ‚Üí ...h/action/support/NodeResponseTracker.java', '.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java', 'server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java', '...pport/IntermediateNodeResponsesTests.java ‚Üí ...ion/support/NodeResponseTrackerTests.java'], 'code': {'cut': ['        assertBusy(', '            () -&gt; assertEquals(', '                0,', '                client().admin().cluster().prepareListTasks().setActions(TestTaskPlugin.TestTaskAction.NAME + "*").get().getTasks().size()', '            ),', '            2,', '            TimeUnit.SECONDS', ' * This class collects and tracks the intermediate responses that can be used to construct the aggregated response. It also gives the', ' * possibility to discard the intermediate results when asked, a use case for this call is when a task is cancelled.', 'public class IntermediateNodeResponses {', '    private static final AlreadyDiscardedException ALREADY_DISCARDED_EXCEPTION = new AlreadyDiscardedException();', '    private volatile boolean discarded = false;', '    public IntermediateNodeResponses(int size) {', '    public IntermediateNodeResponses(Collection&lt;Object&gt; array) {', '     * This method marks the responses as discarded and discards the results collected to free up the resources', '    public void discard() {', '        if (discarded == false) {', '            discarded = true;', '    public boolean isComplete() {', '        return discarded == false &amp;&amp; expectedResponses == counter.get();', '    public boolean isDiscarded() {', '        return discarded;', '        if (discarded) {', '            return false;', '        }', '        if (responses.compareAndSet(nodeIndex, null, response)) {', '     return true;', ' } else {', '    public Object getResponse(int nodeIndex) throws AlreadyDiscardedException {', '        if (discarded) {', '            throw ALREADY_DISCARDED_EXCEPTION;', '    public int size() throws AlreadyDiscardedException {', '        if (discarded) {', '            throw ALREADY_DISCARDED_EXCEPTION;', '    public static class AlreadyDiscardedException extends Exception {}', 'import org.elasticsearch.action.support.IntermediateNodeResponses;', ' IntermediateNodeResponses responseCollector,', '        } catch (IntermediateNodeResponses.AlreadyDiscardedException exception) {', '        private final IntermediateNodeResponses responseCollector;', ' responseCollector = new IntermediateNodeResponses(nodeIds.size());', '                    responseCollector.discard();', '            if (responseCollector.maybeAddResponse(nodeIndex, response) &amp;&amp; responseCollector.isComplete()) {', '', '            if (responseCollector.maybeAddResponse(nodeIndex, t) &amp;&amp; responseCollector.isComplete()) {', '                response = newResponse(request, responseCollector, unavailableShardCount, nodeIds, clusterState);', '            if (responseCollector.isComplete() &amp;&amp; response != null) {', '            if ((task instanceof CancellableTask t) &amp;&amp; t.notifyIfCancelled(listener)) {', '                responseCollector.discard();', '            }', 'import org.elasticsearch.action.support.IntermediateNodeResponses;', '    void newResponse(Task task, NodesRequest request, IntermediateNodeResponses responseCollector, ActionListener&lt;NodesResponse&gt; listener) {', '        } catch (IntermediateNodeResponses.AlreadyDiscardedException exception) {', '        private final IntermediateNodeResponses responseCollector;', '            this.responseCollector = new IntermediateNodeResponses(request.concreteNodes().length);', '                    responseCollector.discard();', ' IntermediateNodeResponses getResponseCollector() {', '            return responseCollector;', '            if (responseCollector.maybeAddResponse(idx, nodeResponse) &amp;&amp; responseCollector.isComplete()) {', '            if (responseCollector.maybeAddResponse(idx, t) &amp;&amp; responseCollector.isComplete()) {', '            threadPool.executor(executor).execute(() -&gt; newResponse(task, request, responseCollector, listener));', '            if ((task instanceof CancellableTask t) &amp;&amp; t.notifyIfCancelled(listener)) {', '                responseCollector.discard();', '            }', 'public class IntermediateNodeResponsesTests extends ESTestCase {', ' IntermediateNodeResponses intermediateNodeResponses = new IntermediateNodeResponses(size);', '        assertTrue(intermediateNodeResponses.isComplete());', '        assertFalse(intermediateNodeResponses.isDiscarded());', ' IntermediateNodeResponses intermediateNodeResponses = new IntermediateNodeResponses(size);', '                intermediateNodeResponses.discard();', '        assertTrue(intermediateNodeResponses.isDiscarded());', ' assertFalse(intermediateNodeResponses.isComplete());', '        expectThrows(IntermediateNodeResponses.AlreadyDiscardedException.class, intermediateNodeResponses::size);', '        expectThrows(IntermediateNodeResponses.AlreadyDiscardedException.class, () -&gt; intermediateNodeResponses.getResponse(0));', ' IntermediateNodeResponses intermediateNodeResponses = new IntermediateNodeResponses(1);'], 'add': ['        assertEquals(', '            0,', '            client().admin().cluster().prepareListTasks().setActions(TestTaskPlugin.TestTaskAction.NAME + "*").get().getTasks().size()', ' * This class tracks the intermediate responses that can be used to construct the aggregated response. It also gives the possibility to', ' * discard the intermediate results when asked, a use case for this call is when the corresponding task is cancelled.', 'public class NodeResponseTracker {', '    private static final DiscardedResponsesException DISCARDED_RESPONSES_EXCEPTION = new DiscardedResponsesException();', '    private final AtomicReferenceArray&lt;Boolean&gt; receivedResponseFromNode;', '    public NodeResponseTracker(int size) {', '        this.receivedResponseFromNode = new AtomicReferenceArray&lt;&gt;(size);', '    public NodeResponseTracker(Collection&lt;Object&gt; array) {', '        this.receivedResponseFromNode = new AtomicReferenceArray&lt;&gt;(responses.length());', '     * This method discards the results collected to free up the resources', '    public void discardIntermediateResponses() {', '        if (responses != null) {', '    public boolean allNodesResponded() {', '        return expectedResponses == counter.get();', '    public boolean responsesDiscarded() {', '        return responses == null;', '        boolean firstEncounter = receivedResponseFromNode.compareAndSet(nodeIndex, null, true);', '        if (firstEncounter) {', ' }', ' if (responsesDiscarded() || firstEncounter == false) {', '', '        responses.set(nodeIndex, response);', '        return true;', '    public Object getResponse(int nodeIndex) throws DiscardedResponsesException {', '        if (responsesDiscarded()) {', '            throw DISCARDED_RESPONSES_EXCEPTION;', '    public int size() throws DiscardedResponsesException {', '        if (responsesDiscarded()) {', '            throw DISCARDED_RESPONSES_EXCEPTION;', '    public static class DiscardedResponsesException extends Exception {}', 'import org.elasticsearch.action.support.NodeResponseTracker;', ' NodeResponseTracker responseCollector,', '        } catch (NodeResponseTracker.DiscardedResponsesException exception) {', '        private final NodeResponseTracker nodeResponseTracker;', '        private volatile boolean cancelled;', ' nodeResponseTracker = new NodeResponseTracker(nodeIds.size());', '            nodeResponseTracker.maybeAddResponse(nodeIndex, response);', '            if (nodeResponseTracker.allNodesResponded()) {', '            nodeResponseTracker.maybeAddResponse(nodeIndex, t);', '            if (nodeResponseTracker.allNodesResponded()) {', '            if (cancelled) {', '                ((CancellableTask) task).notifyIfCancelled(listener);', '                return;', '            }', '', '                response = newResponse(request, nodeResponseTracker, unavailableShardCount, nodeIds, clusterState);', '            if (response != null) {', '            cancelled = (task instanceof CancellableTask t) &amp;&amp; t.isCancelled();', '            nodeResponseTracker.discardIntermediateResponses();', 'import org.elasticsearch.action.support.NodeResponseTracker;', '    void newResponse(Task task, NodesRequest request, NodeResponseTracker responseCollector, ActionListener&lt;NodesResponse&gt; listener) {', '        } catch (NodeResponseTracker.DiscardedResponsesException exception) {', '        private final NodeResponseTracker nodeResponseTracker;', '        private volatile boolean cancelled;', '            this.nodeResponseTracker = new NodeResponseTracker(request.concreteNodes().length);', ' NodeResponseTracker getNodeResponseTracker() {', '            return nodeResponseTracker;', '            nodeResponseTracker.maybeAddResponse(idx, nodeResponse);', '            if (nodeResponseTracker.allNodesResponded()) {', '            nodeResponseTracker.maybeAddResponse(idx, t);', '            if (nodeResponseTracker.allNodesResponded()) {', '            if (cancelled) {', '                ((CancellableTask) task).notifyIfCancelled(listener);', '                return;', '            }', '', '            threadPool.executor(executor).execute(() -&gt; newResponse(task, request, nodeResponseTracker, listener));', '            cancelled = (task instanceof CancellableTask t) &amp;&amp; t.isCancelled();', '            nodeResponseTracker.discardIntermediateResponses();', 'public class NodeResponseTrackerTests extends ESTestCase {', ' NodeResponseTracker intermediateNodeResponses = new NodeResponseTracker(size);', '        assertTrue(intermediateNodeResponses.allNodesResponded());', '        assertFalse(intermediateNodeResponses.responsesDiscarded());', ' NodeResponseTracker intermediateNodeResponses = new NodeResponseTracker(size);', '                intermediateNodeResponses.discardIntermediateResponses();', '        assertTrue(intermediateNodeResponses.responsesDiscarded());', ' assertTrue(intermediateNodeResponses.allNodesResponded());', '        expectThrows(NodeResponseTracker.DiscardedResponsesException.class, intermediateNodeResponses::size);', '        expectThrows(NodeResponseTracker.DiscardedResponsesException.class, () -&gt; intermediateNodeResponses.getResponse(0));', ' NodeResponseTracker intermediateNodeResponses = new NodeResponseTracker(2);']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/b07aa5c806616a86470980c2de997444d9c53a98', 'description': ['\n       Test TransportBroadcastByNodeAction\n    '], 'position': ['.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java', 'server/src/test/java/org/elasticsearch/action/support/NodeResponseTrackerTests.java', '.../org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeActionTests.java', 'server/src/test/java/org/elasticsearch/action/support/nodes/TransportNodesActionTests.java'], 'code': {'cut': ['    public void testCompletion() throws Exception {', '    public void testCancellation() {', '        int size = randomIntBetween(2, 10);', '        int cancelAt = randomIntBetween(0, size - 2);', '    public void testResponseIsRegistredOnlyOnce() throws Exception {', '        action.new AsyncAction(cancelledTask(), request, listener).start();', '', '        int cancelAt = randomIntBetween(1, capturedRequests.values().size() - 2);'], 'add': ['', '        // For testing purposes', '        public NodeResponseTracker getNodeResponseTracker() {', '            return nodeResponseTracker;', '        }', '    public void testAllResponsesReceived() throws Exception {', '    public void testDiscardingResults() {', '        int size = randomIntBetween(1, 10);', '        int cancelAt = randomIntBetween(0, Math.max(0, size - 2));', '    public void testResponseIsRegisteredOnlyOnce() throws Exception {', '        final CancellableTask task = new CancellableTask(randomLong(), "transport", "action", "", null, emptyMap());', '        TransportBroadcastByNodeAction&lt;Request, Response, TransportBroadcastByNodeAction.EmptyResult&gt;.AsyncAction asyncAction =', '            action.new AsyncAction(task, request, listener);', '        asyncAction.start();', '        int cancelAt = randomIntBetween(0, Math.max(0, capturedRequests.size() - 2));', '        int i = 0;', '            if (cancelAt == i) {', '                TaskCancelHelper.cancel(task, "simulated");', '            }', '            i++;', '        assertTrue(asyncAction.getNodeResponseTracker().responsesDiscarded());', '        int cancelAt = randomIntBetween(0, Math.max(0, capturedRequests.values().size() - 2));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/df76008855da391b174afc9e364f5a509775e85d', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/1433a98d56d34b5d2c404d21eaff14dff10e0526', 'description': ['\n       Listener will always be notified when cancelled\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java', 'server/src/test/java/org/elasticsearch/action/support/nodes/TransportNodesActionTests.java'], 'code': {'cut': ['    void newResponse(Task task, NodesRequest request, NodeResponseTracker responseCollector, ActionListener&lt;NodesResponse&gt; listener) {', '        try {', '            for (int i = 0; i &lt; responseCollector.size(); ++i) {', '                Object response = responseCollector.getResponse(i);', '                if (responseCollector.getResponse(i)instanceof FailedNodeException failedNodeException) {', '                    failures.add(failedNodeException);', '                } else {', '                    responses.add(nodeResponseClass.cast(response));', '                }', '', '            newResponseAsync(task, request, responses, failures, listener);', '        } catch (NodeResponseTracker.DiscardedResponsesException exception) {', '            logger.debug("Task was already cancelled");', '            threadPool.executor(executor).execute(() -&gt; newResponse(task, request, nodeResponseTracker, listener));', '    public void testNewResponseNullArray() {', '    public void testNewResponse() {'], 'add': ['    void newResponse(Task task, NodesRequest request, NodeResponseTracker responseCollector, ActionListener&lt;NodesResponse&gt; listener)', '        throws NodeResponseTracker.DiscardedResponsesException {', '        for (int i = 0; i &lt; responseCollector.size(); ++i) {', '            Object response = responseCollector.getResponse(i);', '            if (responseCollector.getResponse(i)instanceof FailedNodeException failedNodeException) {', '                failures.add(failedNodeException);', '            } else {', '                responses.add(nodeResponseClass.cast(response));', '', '        newResponseAsync(task, request, responses, failures, listener);', '            threadPool.executor(executor).execute(() -&gt; {', '                try {', '                    newResponse(task, request, nodeResponseTracker, listener);', '                } catch (NodeResponseTracker.DiscardedResponsesException e) {', '                    if (cancelled) {', '                        ((CancellableTask) task).notifyIfCancelled(listener);', '                    }', '                }', '            });', '    public void testNewResponseNullArray() throws Exception {', '    public void testNewResponse() throws Exception {']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/ccbc336becaf8fb94c08d254a4b83e09e013cbfd', 'description': ['\n       Bug fix, wrap failures with FailedNodeException\n    '], 'position': ['.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java', 'server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java'], 'code': {'cut': ['        NodeResponseTracker responseCollector,', '            for (int i = 0; i &lt; responseCollector.size(); i++) {', '                Object response = responseCollector.getResponse(i);', '            nodeResponseTracker.maybeAddResponse(nodeIndex, t);', '     * @param responseCollector All node-level responses collected so far', '     * @throws NullPointerException if {@code nodesResponses} is {@code null}', '    void newResponse(Task task, NodesRequest request, NodeResponseTracker responseCollector, ActionListener&lt;NodesResponse&gt; listener)', '        if (responseCollector == null) {', '        for (int i = 0; i &lt; responseCollector.size(); ++i) {', '            Object response = responseCollector.getResponse(i);', '            if (responseCollector.getResponse(i)instanceof FailedNodeException failedNodeException) {', '            nodeResponseTracker.maybeAddResponse(idx, t);'], 'add': ['        NodeResponseTracker nodeResponseTracker,', '            for (int i = 0; i &lt; nodeResponseTracker.size(); i++) {', '                Object response = nodeResponseTracker.getResponse(i);', '            nodeResponseTracker.maybeAddResponse(nodeIndex, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t));', '     * @param nodeResponseTracker All node-level responses collected so far', '     * @throws NodeResponseTracker.DiscardedResponsesException if {@code nodeResponseTracker} has already discarded the intermediate results', '    void newResponse(Task task, NodesRequest request, NodeResponseTracker nodeResponseTracker, ActionListener&lt;NodesResponse&gt; listener)', '        if (nodeResponseTracker == null) {', '        for (int i = 0; i &lt; nodeResponseTracker.size(); ++i) {', '            Object response = nodeResponseTracker.getResponse(i);', '            if (nodeResponseTracker.getResponse(i)instanceof FailedNodeException failedNodeException) {', '            nodeResponseTracker.maybeAddResponse(idx, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/e7ac678b5894ce794c15adcb484817699324a636', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/2224e1c1589793a7a7afc536920fc23144c5e101', 'description': ['\n       Propagate the task cancellation to the listener\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/NodeResponseTracker.java', '.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java', 'server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java', 'server/src/test/java/org/elasticsearch/action/support/NodeResponseTrackerTests.java'], 'code': {'cut': ['    private static final DiscardedResponsesException DISCARDED_RESPONSES_EXCEPTION = new DiscardedResponsesException();', '', '     * This method discards the results collected to free up the resources', '    public void discardIntermediateResponses() {', '            throw DISCARDED_RESPONSES_EXCEPTION;', '            throw DISCARDED_RESPONSES_EXCEPTION;', '    public static class DiscardedResponsesException extends Exception {}', '    ) {', '        try {', '            for (int i = 0; i &lt; nodeResponseTracker.size(); i++) {', '                Object response = nodeResponseTracker.getResponse(i);', '                if (response instanceof FailedNodeException exception) {', '                    totalShards += nodes.get(exception.nodeId()).size();', '                    for (ShardRouting shard : nodes.get(exception.nodeId())) {', '                        exceptions.add(new DefaultShardOperationFailedException(shard.getIndexName(), shard.getId(), exception));', '                    }', '                } else {', '                    @SuppressWarnings("unchecked")', '                    NodeResponse nodeResponse = (NodeResponse) response;', '                    broadcastByNodeResponses.addAll(nodeResponse.results);', '                    totalShards += nodeResponse.getTotalShards();', '                    successfulShards += nodeResponse.getSuccessfulShards();', '                    for (BroadcastShardOperationFailedException throwable : nodeResponse.getExceptions()) {', '                        if (TransportActions.isShardNotAvailableException(throwable) == false) {', '                            exceptions.add(', '                                new DefaultShardOperationFailedException(', '                                    throwable.getShardId().getIndexName(),', '                                    throwable.getShardId().getId(),', '                                    throwable', '                                )', '                            );', '                        }', '            totalShards += unavailableShardCount;', '            int failedShards = exceptions.size();', '            return newResponse(request, totalShards, successfulShards, failedShards, broadcastByNodeResponses, exceptions, clusterState);', '        } catch (NodeResponseTracker.DiscardedResponsesException exception) {', '            return null;', '        private volatile boolean cancelled;', '            if (cancelled) {', '                ((CancellableTask) task).notifyIfCancelled(listener);', '            cancelled = (task instanceof CancellableTask t) &amp;&amp; t.isCancelled();', '            nodeResponseTracker.discardIntermediateResponses();', '        private volatile boolean cancelled;', '            if (cancelled) {', '                ((CancellableTask) task).notifyIfCancelled(listener);', ' if (cancelled) {', '     ((CancellableTask) task).notifyIfCancelled(listener);', ' }', '            cancelled = (task instanceof CancellableTask t) &amp;&amp; t.isCancelled();', '            nodeResponseTracker.discardIntermediateResponses();', '                intermediateNodeResponses.discardIntermediateResponses();'], 'add': ['    private volatile Exception causeOfDiscarding;', '     * This method discards the results collected to free up the resources.', '    public void discardIntermediateResponses(Exception cause) {', '            this.causeOfDiscarding = cause;', '            throw new DiscardedResponsesException(causeOfDiscarding);', '            throw new DiscardedResponsesException(causeOfDiscarding);', '    /**', '     * This exception is thrown when the {@link NodeResponseTracker} is asked to give information about the responses after they have been', '     * discarded.', '     */', '    public static class DiscardedResponsesException extends Exception {', '', '        public DiscardedResponsesException(Exception cause) {', '            super(cause);', '        }', '    }', '    ) throws NodeResponseTracker.DiscardedResponsesException {', '        for (int i = 0; i &lt; nodeResponseTracker.size(); i++) {', '            Object response = nodeResponseTracker.getResponse(i);', '            if (response instanceof FailedNodeException exception) {', '                totalShards += nodes.get(exception.nodeId()).size();', '                for (ShardRouting shard : nodes.get(exception.nodeId())) {', '                    exceptions.add(new DefaultShardOperationFailedException(shard.getIndexName(), shard.getId(), exception));', '                }', '            } else {', '                @SuppressWarnings("unchecked")', '                NodeResponse nodeResponse = (NodeResponse) response;', '                broadcastByNodeResponses.addAll(nodeResponse.results);', '                totalShards += nodeResponse.getTotalShards();', '                successfulShards += nodeResponse.getSuccessfulShards();', '                for (BroadcastShardOperationFailedException throwable : nodeResponse.getExceptions()) {', '                    if (TransportActions.isShardNotAvailableException(throwable) == false) {', '                        exceptions.add(', '                            new DefaultShardOperationFailedException(', '                                throwable.getShardId().getIndexName(),', '                                throwable.getShardId().getId(),', '                                throwable', '                            )', '                        );', '        totalShards += unavailableShardCount;', '        int failedShards = exceptions.size();', '        return newResponse(request, totalShards, successfulShards, failedShards, broadcastByNodeResponses, exceptions, clusterState);', '            if ((task instanceof CancellableTask t) &amp;&amp; t.notifyIfCancelled(listener)) {', '            } catch (NodeResponseTracker.DiscardedResponsesException e) {', '                // We propagate the reason that the results, in this case the task cancellation, in case the listener needs to take', '                // follow-up actions', '                listener.onFailure((Exception) e.getCause());', '            try {', '                if (task instanceof CancellableTask t) {', '                    t.ensureNotCancelled();', '                }', '            } catch (TaskCancelledException e) {', '                nodeResponseTracker.discardIntermediateResponses(e);', '            }', 'import org.elasticsearch.tasks.TaskCancelledException;', '            if ((task instanceof CancellableTask t) &amp;&amp; t.notifyIfCancelled(listener)) {', ' // We propagate the reason that the results, in this case the task cancellation, in case the listener needs to take', ' // follow-up actions', ' listener.onFailure((Exception) e.getCause());', '            try {', '                if (task instanceof CancellableTask t) {', '                    t.ensureNotCancelled();', '                }', '            } catch (TaskCancelledException e) {', '                nodeResponseTracker.discardIntermediateResponses(e);', '            }', '                intermediateNodeResponses.discardIntermediateResponses(new Exception("simulated"));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/3e73db99cbcf74b9607515097728410790221f48', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/51ab1ef469a6de3cb45e05b71ba16b83ffdfb6ca', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/62a2c24c56ce34299f58ddaa7f539eb09619d98f', 'description': ['\n       Enrich javadoc\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/NodeResponseTracker.java'], 'code': {'cut': [' * This class tracks the intermediate responses that can be used to construct the aggregated response. It also gives the possibility to', ' * discard the intermediate results when asked, a use case for this call is when the corresponding task is cancelled.', '    private final int expectedResponses;', '    private final AtomicInteger counter = new AtomicInteger();', '        this.expectedResponses = size;', '        this.expectedResponses = responses.length();', '     * This method discards the results collected to free up the resources.', '        return expectedResponses == counter.get();', ' counter.incrementAndGet();', '        return expectedResponses;'], 'add': [' * This class tracks the intermediate responses that will be used to create aggregated cluster response to a request. It also gives the', ' * possibility to discard the intermediate results when asked, for example when the initial request is cancelled, in order to release the', ' * resources.', '    private final AtomicInteger receivedResponsesCounter = new AtomicInteger();', '     * This method discards the results collected so far to free up the resources.', '     * @param cause the discarding, this will be communicated if they try to access the discarded results', '        return receivedResponseFromNode.length() == receivedResponsesCounter.get();', ' receivedResponsesCounter.incrementAndGet();', '    /**', "     * Returns the tracked response or null if the response hasn't been received yet for a specific index that represents a node of the", '     * cluster.', '     * @throws DiscardedResponsesException if the responses have been discarded', '     */', '    /**', '     * The count of the expected responses', '     * @throws DiscardedResponsesException if the responses have been discarded', '     */', '        return receivedResponseFromNode.length();']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/660c16bd1f7d285845513cc75bd87ad94990daa5', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/f54a7aceafe56464520cf7f5f480879858863b52', 'description': ['\n       Polishing NodeResponseTracker\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/NodeResponseTracker.java', '.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java', 'server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java', 'server/src/test/java/org/elasticsearch/action/support/NodeResponseTrackerTests.java'], 'code': {'cut': ['    private final AtomicInteger receivedResponsesCounter = new AtomicInteger();', '        return receivedResponseFromNode.length() == receivedResponsesCounter.get();', ' receivedResponsesCounter.incrementAndGet();', '    /**', '     * The count of the expected responses', '     * @throws DiscardedResponsesException if the responses have been discarded', '     */', '    public int size() throws DiscardedResponsesException {', '        if (responsesDiscarded()) {', '            throw new DiscardedResponsesException(causeOfDiscarding);', '        }', '        for (int i = 0; i &lt; nodeResponseTracker.size(); i++) {', '        for (int i = 0; i &lt; nodeResponseTracker.size(); ++i) {', '        int size = randomIntBetween(1, 10);', '        NodeResponseTracker intermediateNodeResponses = new NodeResponseTracker(size);', '        for (int i = 0; i &lt; size; i++) {', '        assertEquals(size, intermediateNodeResponses.size());', '        for (int i = 0; i &lt; size; i++) {', '        int size = randomIntBetween(1, 10);', '        int cancelAt = randomIntBetween(0, Math.max(0, size - 2));', '        NodeResponseTracker intermediateNodeResponses = new NodeResponseTracker(size);', '        for (int i = 0; i &lt; size; i++) {', ' expectThrows(NodeResponseTracker.DiscardedResponsesException.class, intermediateNodeResponses::size);'], 'add': ['    private final AtomicInteger counter = new AtomicInteger();', '        return counter.get() == expectedResponseCount();', ' counter.incrementAndGet();', '    public int expectedResponseCount() {', '        for (int i = 0; i &lt; nodeResponseTracker.expectedResponseCount(); i++) {', '        for (int i = 0; i &lt; nodeResponseTracker.expectedResponseCount(); ++i) {', '        int nodes = randomIntBetween(1, 10);', '        NodeResponseTracker intermediateNodeResponses = new NodeResponseTracker(nodes);', '        for (int i = 0; i &lt; nodes; i++) {', '        assertEquals(nodes, intermediateNodeResponses.expectedResponseCount());', '        for (int i = 0; i &lt; nodes; i++) {', '        int nodes = randomIntBetween(1, 10);', '        int cancelAt = randomIntBetween(0, Math.max(0, nodes - 2));', '        NodeResponseTracker intermediateNodeResponses = new NodeResponseTracker(nodes);', '        for (int i = 0; i &lt; nodes; i++) {', ' assertEquals(nodes, intermediateNodeResponses.expectedResponseCount());']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/21663a0981e97966f3c96aa06205d02987dd3a32', 'description': ['\n       Update docs/changelog/82685.yaml\n    '], 'position': ['docs/changelog/82685.yaml'], 'code': {'cut': [], 'add': ['pr: 82685', 'summary: Discard intermediate results upon cancellation for stats endpoints', 'area: Stats', 'type: bug', 'issues:', ' - 82337']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/e596a6131bf80e50fedea553b9221fba76ec5956', 'description': ['\n       Merge maybeAddResponse and isComplete\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/NodeResponseTracker.java', '.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java', 'server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java', 'server/src/test/java/org/elasticsearch/action/support/NodeResponseTrackerTests.java'], 'code': {'cut': ['    public boolean allNodesResponded() {', '        return counter.get() == expectedResponseCount();', '    }', '', '     * @return true if it was successfully stored, else false', '    public boolean maybeAddResponse(int nodeIndex, Object response) {', '        if (firstEncounter) {', '            counter.incrementAndGet();', '        }', '        if (responsesDiscarded() || firstEncounter == false) {', '        responses.set(nodeIndex, response);', '        return true;', '            nodeResponseTracker.maybeAddResponse(nodeIndex, response);', '            if (nodeResponseTracker.allNodesResponded()) {', '            nodeResponseTracker.maybeAddResponse(nodeIndex, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t));', '            if (nodeResponseTracker.allNodesResponded()) {', '            nodeResponseTracker.maybeAddResponse(idx, nodeResponse);', '            if (nodeResponseTracker.allNodesResponded()) {', '            nodeResponseTracker.maybeAddResponse(idx, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t));', '            if (nodeResponseTracker.allNodesResponded()) {', '            assertTrue(intermediateNodeResponses.maybeAddResponse(i, randomBoolean() ? i : new Exception("from node " + i)));', '        assertTrue(intermediateNodeResponses.allNodesResponded());', '            boolean added = intermediateNodeResponses.maybeAddResponse(i, randomBoolean() ? i : new Exception("from node " + i));', '            if (i &lt; cancelAt) {', '                assertTrue(added);', '            } else {', '                assertFalse(added);', '            }', '        assertTrue(intermediateNodeResponses.allNodesResponded());', '        NodeResponseTracker intermediateNodeResponses = new NodeResponseTracker(2);', '        assertTrue(intermediateNodeResponses.maybeAddResponse(0, "response1"));', '        assertFalse(intermediateNodeResponses.maybeAddResponse(0, "response2"));'], 'add': ['     * @return true if this was the first encounter of the last expected response, else false', '    public boolean trackResponseAndCheckIfLast(int nodeIndex, Object response) {', '        if (firstEncounter == false) {', '        if (responsesDiscarded() == false) {', '            responses.set(nodeIndex, response);', '        }', '        return counter.incrementAndGet() == expectedResponseCount();', '            if (nodeResponseTracker.trackResponseAndCheckIfLast(nodeIndex, response)) {', '            if (nodeResponseTracker.trackResponseAndCheckIfLast(', '                nodeIndex,', '                new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t)', '            )) {', '            if (nodeResponseTracker.trackResponseAndCheckIfLast(idx, nodeResponse)) {', '            if (nodeResponseTracker.trackResponseAndCheckIfLast(idx, new FailedNodeException(nodeId, "Failed node [" + nodeId + "]", t))) {', '            boolean isLast = i == nodes - 1;', '            assertEquals(', '                isLast,', '                intermediateNodeResponses.trackResponseAndCheckIfLast(i, randomBoolean() ? i : new Exception("from node " + i))', '            );', '            boolean isLast = i == nodes - 1;', '            assertEquals(', '                isLast,', '                intermediateNodeResponses.trackResponseAndCheckIfLast(i, randomBoolean() ? i : new Exception("from node " + i))', '            );', '        NodeResponseTracker intermediateNodeResponses = new NodeResponseTracker(1);', '        assertTrue(intermediateNodeResponses.trackResponseAndCheckIfLast(0, "response1"));', '        assertFalse(intermediateNodeResponses.trackResponseAndCheckIfLast(0, "response2"));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/e867b69e13e7fd54048ffd523db36e2a20f169a0', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/48ae87cb9638b66eba5f9006cdd19d9817053276', 'description': ['\n       Improve listener addition and add assertions\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/NodeResponseTracker.java', '.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java', 'server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java', 'server/src/main/java/org/elasticsearch/tasks/CancellableTask.java', '...rc/test/java/org/elasticsearch/action/admin/cluster/node/tasks/CancellableTasksTests.java', 'server/src/test/java/org/elasticsearch/action/support/NodeResponseTrackerTests.java'], 'code': {'cut': ["     * This method stores a new node response if it is first response encountered from this node and the intermediate responses haven't", '     * been discarded yet. Checking that this is the first time we have received a response from this node is a defensive mechanism to', '     * protect against the possibility of double invocation.', '     * @return true if this was the first encounter of the last expected response, else false', '        boolean firstEncounter = receivedResponseFromNode.compareAndSet(nodeIndex, null, true);', '        if (firstEncounter == false) {', '            return false;', '        }', '                if (cancellableTask.registerListener(this) == false) {', '                    cancellableTask.notifyIfCancelled(listener);', '                    return;', '                }', '                if (task instanceof CancellableTask t) {', '                    t.ensureNotCancelled();', '                }', '                if (cancellableTask.registerListener(this) == false) {', '                    cancellableTask.notifyIfCancelled(listener);', '                    return;', '                }', '                if (task instanceof CancellableTask t) {', '                    t.ensureNotCancelled();', '                }', '     * This method registers a listener that needs to be notified when this task is cancelled given that the task is not cancelled yet.', '    public final boolean registerListener(CancellationListener listener) {', ' return false;', '        return listeners.add(listener);', '        assertTrue(((CancellableTask) mainTask).registerListener(() -&gt; listenerCalledUponCancellation.set(true)));', '            // Verify the registered listeners have been notified', '            assertTrue(listenerCalledUponCancellation.get());', '            // Verify that a cancellation listener cannot be added to an already cancelled task', '            assertFalse(((CancellableTask) mainTask).registerListener(() -&gt; {}));', '        Task mainTask = startCancellableTestNodesAction(true, runNodesCount, blockedNodesCount, new ActionListener&lt;NodesResponse&gt;() {', '    public void testResponseIsRegisteredOnlyOnce() throws Exception {', '        assertFalse(intermediateNodeResponses.trackResponseAndCheckIfLast(0, "response2"));', '        assertEquals("response1", intermediateNodeResponses.getResponse(0));'], 'add': ["     * This method stores a new node response if the intermediate responses haven't been discarded yet. The method asserts that this is the", '     * first response encountered from this node to protect from miscounting the responses in case of a  double invocation.', "     * @return true if all the nodes' responses have been received, else false", '        assert receivedResponseFromNode.compareAndSet(nodeIndex, null, true);', '                cancellableTask.addListener(this);', '            assert task instanceof CancellableTask : "task must be cancellable";', '                ((CancellableTask) task).ensureNotCancelled();', '                cancellableTask.addListener(this);', '            assert task instanceof CancellableTask : "task must be cancellable";', '                ((CancellableTask) task).ensureNotCancelled();', '     * This method adds a listener that needs to be notified if this task is cancelled.', '    public final void addListener(CancellationListener listener) {', '        synchronized (this) {', '            if (this.isCancelled == false) {', '                listeners.add(listener);', '            }', '        }', ' listener.onCancelled();', '    /**', '     * Simulates a cancellation listener and sets a flag to true if the task was cancelled', '     */', '    static class CancellableTestCancellationListener implements CancellableTask.CancellationListener {', '', '        final AtomicBoolean calledUponCancellation = new AtomicBoolean(false);', '', '        @Override', '        public void onCancelled() {', '            calledUponCancellation.set(true);', '        }', '    }', '', '        CancellableTestCancellationListener listenerAddedBeforeCancellation = new CancellableTestCancellationListener();', '        ((CancellableTask) mainTask).addListener(listenerAddedBeforeCancellation);', '', '            CancellableTestCancellationListener listenerAddedAfterCancellation = new CancellableTestCancellationListener();', '            ((CancellableTask) mainTask).addListener(listenerAddedAfterCancellation);', '', '            // Verify both cancellation listeners have been notified', '            assertTrue(listenerAddedBeforeCancellation.calledUponCancellation.get());', '            assertTrue(listenerAddedAfterCancellation.calledUponCancellation.get());', '        Task mainTask = startCancellableTestNodesAction(true, runNodesCount, blockedNodesCount, new ActionListener&lt;&gt;() {', '    public void testResponseIsRegisteredOnlyOnce() {', '        expectThrows(AssertionError.class, () -&gt; intermediateNodeResponses.trackResponseAndCheckIfLast(0, "response2"));']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/a614cd84918ed9b9f5b3f6cabf92597febb66545', 'description': ['\n       Simplify tracking nodes responding after discarding\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/NodeResponseTracker.java', '.../java/org/elasticsearch/action/support/broadcast/node/TransportBroadcastByNodeAction.java', 'server/src/main/java/org/elasticsearch/action/support/nodes/TransportNodesAction.java', 'server/src/test/java/org/elasticsearch/action/support/NodeResponseTrackerTests.java'], 'code': {'cut': ['    private final AtomicReferenceArray&lt;Boolean&gt; receivedResponseFromNode;', '        this.receivedResponseFromNode = new AtomicReferenceArray&lt;&gt;(size);', '        this.receivedResponseFromNode = new AtomicReferenceArray&lt;&gt;(responses.length());', "     * This method stores a new node response if the intermediate responses haven't been discarded yet. The method asserts that this is the", '     * first response encountered from this node to protect from miscounting the responses in case of a  double invocation.', '        assert receivedResponseFromNode.compareAndSet(nodeIndex, null, true);', '            responses.set(nodeIndex, response);', '        return counter.incrementAndGet() == expectedResponseCount();', '    public int expectedResponseCount() {', '        return receivedResponseFromNode.length();', '        for (int i = 0; i &lt; nodeResponseTracker.expectedResponseCount(); i++) {', '        for (int i = 0; i &lt; nodeResponseTracker.expectedResponseCount(); ++i) {', '        assertEquals(nodes, intermediateNodeResponses.expectedResponseCount());', '        assertEquals(nodes, intermediateNodeResponses.expectedResponseCount());'], 'add': ['    private final int expectedResponsesCount;', '        this.expectedResponsesCount = size;', '        this.expectedResponsesCount = array.size();', "     * This method stores a new node response if the intermediate responses haven't been discarded yet. If the responses are not discarded", '     * the method asserts that this is the first response encountered from this node to protect from miscounting the responses in case of a', '     * double invocation. If the responses have been discarded we accept this risk for simplicity.', ' assert responses.compareAndSet(nodeIndex, null, response) : "a response should be recorded only once";', '        return counter.incrementAndGet() == getExpectedResponseCount();', '    public int getExpectedResponseCount() {', '        return expectedResponsesCount;', '        for (int i = 0; i &lt; nodeResponseTracker.getExpectedResponseCount(); i++) {', '        for (int i = 0; i &lt; nodeResponseTracker.getExpectedResponseCount(); ++i) {', '        assertEquals(nodes, intermediateNodeResponses.getExpectedResponseCount());', '        assertEquals(nodes, intermediateNodeResponses.getExpectedResponseCount());']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/c28e535e67d544a3b389fa79203190b72d330b53', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/aa5adbda4a207687577364c2b6fa7d23a2412694', 'description': ["\n       Merge branch 'master' into stats-discard-intermediate-results-on-canc‚Ä¶\n    "], 'position': [], 'code': {'cut': [], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/82685/commits/34437cff932415d02fa2e1d9bb3984a91ef84ed6', 'description': ['\n       Bug fix\n    '], 'position': ['server/src/main/java/org/elasticsearch/action/support/NodeResponseTracker.java'], 'code': {'cut': ['            assert responses.compareAndSet(nodeIndex, null, response) : "a response should be recorded only once";'], 'add': ['            boolean firstEncounter = responses.compareAndSet(nodeIndex, null, response);', '            assert firstEncounter : "a response should be tracked only once";']}}], 'title': 'Discard intermediate results upon cancellation for stats endpoints'}
        , {'origin_url': 'https://github.com/elastic/elasticsearch/pull/82664', 'comment': [" We don't set any Xmx limit. On larger workstations this means that Gradle will take up to 25% of system memory on newer JVMs which is needlessly much on e.g. a 64G RAM workstation. It seems 4G as a limit should work fine and allow for faster local builds by leaving more memory for the rest of the system? "], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/82664/commits/864abe114d80b03c8798556b231b62048ce4c7ee', 'description': ['\n       Limit Gradle JVM Heap to 4G\n    '], 'position': ['gradle.properties'], 'code': {'cut': ['org.gradle.jvmargs=-XX:+HeapDumpOnOutOfMemoryError -Xss2m  --add-exports jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED'], 'add': ['org.gradle.jvmargs=-XX:+HeapDumpOnOutOfMemoryError -Xss2m -Xmx4g --add-exports jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED']}}], 'title': 'Limit Gradle JVM Heap to 4G'}
        , {'origin_url': 'https://github.com/elastic/elasticsearch/pull/81159', 'comment': [' Reduces cardinality of test data in order to avoid OOMs in the TimeSeriesMetricsIT test until we have real time series solution. Closes #81045 '], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/81159/commits/7e4711cfb0154a6535b03b8439f56783ceedaf8f', 'description': ['\n       Fix OOM in TimeSeriesMetricsIT test\n    '], 'position': ['...rc/internalClusterTest/java/org/elasticsearch/timeseries/support/TimeSeriesMetricsIT.java'], 'code': {'cut': ['        int bucketCount = scaledRandomIntBetween(iterationBuckets * 2, iterationBuckets * 100);'], 'add': ['        int bucketCount = scaledRandomIntBetween(iterationBuckets * 2, iterationBuckets * 10);']}}], 'title': 'Fix OOM in TimeSeriesMetricsIT test'}
        , {'origin_url': 'https://github.com/elastic/elasticsearch/pull/80890', 'comment': [" Do not merge This PR is a pure experimental code that uses the JFR old object sampling events to capture a list of suspect allocations, that might be leading to an Out of Memory error. In it's basic form the code does the following:  It installs a GC tenured area event notification for a given threshold of available memory. When the tenured (old object) area in the heap reaches this threshold, the JVM will send us a notification saying we are there. Upon receiving a low memory event from the JVM, we trigger the JFR sampling looking for objects that are allocated and rooted into old objects. We sample periodically, for a prolonged period of time to be able to truly capture the culprits. The longer the sampling period is, the higher the chances are that we'll find the source of heap exhaustion.  ", ' This is simply some test code to cause ES to go OOM. '], 'commit_code': [{'commit_id': 'https://github.com/elastic/elasticsearch/pull/80890/commits/032636047208bcd668977c04c8ba1f001f9a9066', 'description': ['\n       WIP: Add old object sampler on OOM\n    '], 'position': ['server/src/main/java/org/elasticsearch/monitor/jvm/HotThreads.java', 'server/src/main/java/org/elasticsearch/monitor/jvm/JvmGcMonitorService.java', 'server/src/main/java/org/elasticsearch/monitor/jvm/OldObjectsSampler.java', 'server/src/main/resources/org/elasticsearch/bootstrap/security.policy'], 'code': {'cut': ['        synchronized (mutex) {', '        }'], 'add': ['    List&lt;Integer[]&gt; damnedList = new ArrayList&lt;&gt;();', '', '        for (;;) {', '            damnedList.add(new Integer[500_000]);', '            Thread.sleep(500);', '        }', '        /*synchronized (mutex) {', '        }*/', 'import javax.management.NotificationEmitter;', 'import java.lang.management.ManagementFactory;', 'import java.lang.management.MemoryNotificationInfo;', 'import java.lang.management.MemoryPoolMXBean;', 'import java.lang.management.MemoryType;', 'import java.lang.management.MemoryUsage;', 'import java.security.AccessController;', 'import java.security.PrivilegedAction;', '    private volatile Cancellable oomMonitorFuture;', '', '', '        AccessController.doPrivileged((PrivilegedAction&lt;Void&gt;) () -&gt; {', '            setupOOMMonitor();', '            return null;', '        });', '    }', '', '    private void setupOOMMonitor() {', '        MemoryPoolMXBean tenuredGen = ManagementFactory.getMemoryPoolMXBeans().stream()', '            .filter(pool -&gt; pool.getType() == MemoryType.HEAP)', '            .filter(MemoryPoolMXBean::isUsageThresholdSupported)', '            .findFirst()', '            .orElseThrow(() -&gt; new IllegalStateException(', '                "Unable to find tenured generation MemoryPoolMXBean. Unsupported JVM?"));', '', '        double threshold = 0.49;', '        MemoryUsage usage = tenuredGen.getUsage();', '        tenuredGen.setCollectionUsageThreshold((int)Math.floor(usage.getMax() * threshold));', '', '        NotificationEmitter notificationEmitter =', '            (NotificationEmitter) ManagementFactory.getMemoryMXBean();', '        notificationEmitter.addNotificationListener((notification, handback) -&gt; {', '            if (MemoryNotificationInfo.MEMORY_COLLECTION_THRESHOLD_EXCEEDED.equals(notification.getType())) {', '                logger.warn("Elasticsearch is running low on Java memory");', '                try {', '                    OldObjectsSampler.dumpMemoryHogSuspects();', '                } catch (Exception x) {', '                    logger.error(":( Unable to dump memory hogs suspects.", x);', '                }', '            }', '        }, null, null);', '/*', ' * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one', ' * or more contributor license agreements. Licensed under the Elastic License', ' * 2.0 and the Server Side Public License, v 1; you may not use this file except', ' * in compliance with, at your election, the Elastic License 2.0 or the Server', ' * Side Public License, v 1.', ' */', '', 'package org.elasticsearch.monitor.jvm;', '', 'import jdk.jfr.Recording;', 'import jdk.jfr.consumer.RecordedEvent;', 'import jdk.jfr.consumer.RecordingFile;', '', 'import org.apache.logging.log4j.LogManager;', 'import org.apache.logging.log4j.Logger;', '', 'import java.io.File;', 'import java.io.IOException;', 'import java.nio.file.Path;', 'import java.util.List;', 'import java.util.concurrent.atomic.AtomicBoolean;', '', 'public class OldObjectsSampler {', '    private static final int NUM_SAMPLES = 3;', '    private static final int SAMPLER_DELAY = 3_000;', '    private static final Logger logger = LogManager.getLogger(OldObjectsSampler.class);', '    private static final AtomicBoolean samplingOn = new AtomicBoolean();', '', '    private static List&lt;RecordedEvent&gt; fromRecording(Recording recording) throws IOException {', '        return RecordingFile.readAllEvents(dump(recording));', '    }', '', '    private static Path dump(Recording recording) throws IOException {', '        Path p = recording.getDestination();', '        if (p == null) {', '            File directory = new File(".");', '            ProcessHandle h = ProcessHandle.current();', '            p = new File(directory.getAbsolutePath(), "recording-" + recording.getId() + "-pid" + h.pid() + ".jfr").toPath();', '            recording.dump(p);', '        }', '        return p;', '    }', '', '    public static void dumpMemoryHogSuspects() throws IOException {', '        if (samplingOn.compareAndSet(false, true) == false) {', '            // Already sampling from a previous OOM event', '            return;', '        }', '        try {', '            for (int counter = 0; counter &lt; NUM_SAMPLES; counter++) {', '                try (Recording r = new Recording()) {', '                    r.enable("jdk.OldObjectSample").withStackTrace().with("cutoff", "infinity");', '                    r.start();', '                    try {', '                        Thread.sleep(SAMPLER_DELAY);', '                    } catch (Exception ignore) {}', '                    r.stop();', '                    List&lt;RecordedEvent&gt; events = fromRecording(r);', '                    if (events.isEmpty() == false) {', '                        logger.warn("Sampling result {}/{}", counter+1, NUM_SAMPLES);', '                        logger.warn(events);', '                    }', '                }', '            }', '        } finally {', '            samplingOn.set(false);', '        }', '    }', '}', '  permission java.lang.management.ManagementPermission "control";', '  permission jdk.jfr.FlightRecorderPermission "accessFlightRecorder";', '  permission java.lang.RuntimePermission "manageProcess";', '  permission java.io.FilePermission "&lt;&lt;ALL FILES&gt;&gt;", "read, write";']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/80890/commits/4a2666279f191418ba9f974da8982f05a83b5716', 'description': ['\n       Small refactor\n    '], 'position': ['server/src/main/java/org/elasticsearch/monitor/jvm/JvmGcMonitorService.java', 'server/src/main/java/org/elasticsearch/monitor/jvm/OldObjectsSampler.java'], 'code': {'cut': ['', '        AccessController.doPrivileged((PrivilegedAction&lt;Void&gt;) () -&gt; {', '            setupOOMMonitor();', '            return null;', '        });', '    private void setupOOMMonitor() {', '        double threshold = 0.49;', '        tenuredGen.setCollectionUsageThreshold((int)Math.floor(usage.getMax() * threshold));', 'import java.util.concurrent.atomic.AtomicBoolean;', '    private static final AtomicBoolean samplingOn = new AtomicBoolean();', '        if (samplingOn.compareAndSet(false, true) == false) {', '            // Already sampling from a previous OOM event', '            return;', '        }', '        try {', '            for (int counter = 0; counter &lt; NUM_SAMPLES; counter++) {', '                try (Recording r = new Recording()) {', '                    r.enable("jdk.OldObjectSample").withStackTrace().with("cutoff", "infinity");', '                    r.start();', '                    try {', '                        Thread.sleep(SAMPLER_DELAY);', '                    } catch (Exception ignore) {}', '                    r.stop();', '                    List&lt;RecordedEvent&gt; events = fromRecording(r);', '                    if (events.isEmpty() == false) {', '                        logger.warn("Sampling result {}/{}", counter+1, NUM_SAMPLES);', '                        logger.warn(events);', '                    }', '        } finally {', '            samplingOn.set(false);'], 'add': ['    public static final Setting&lt;Float&gt; GC_OOM_SAMPLING_THRESHOLD = Setting.floatSetting(', '        "monitor.jvm.gc.oom.sampling.threshold",', '        0.90f,', '        0.50f,', '        Property.NodeScope', '    );', '', '        if (enabled) {', '            AccessController.doPrivileged((PrivilegedAction&lt;Void&gt;) () -&gt; {', '                setupOOMMonitor(GC_OOM_SAMPLING_THRESHOLD.get(settings));', '                return null;', '            });', '        }', '    private void setupOOMMonitor(float threshold) {', '        tenuredGen.setCollectionUsageThreshold((int)Math.floor(((float)usage.getMax()) * threshold));', '        for (int counter = 0; counter &lt; NUM_SAMPLES; counter++) {', '            try (Recording r = new Recording()) {', '                r.enable("jdk.OldObjectSample").withStackTrace().with("cutoff", "infinity");', '                r.start();', '                try {', '                    Thread.sleep(SAMPLER_DELAY);', '                } catch (Exception ignore) {}', '                r.stop();', '                List&lt;RecordedEvent&gt; events = fromRecording(r);', '                if (events.isEmpty() == false) {', '                    logger.warn("Sampling result {}/{}", counter+1, NUM_SAMPLES);', '                    logger.warn(events);']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/80890/commits/3eb9c030b5c098e44c509c1382d0c4b1855a5bce', 'description': ['\n       Coalesce stacks for readability\n    '], 'position': ['server/src/main/java/org/elasticsearch/monitor/jvm/OldObjectsSampler.java'], 'code': {'cut': ['                    logger.warn("Sampling result {}/{}", counter+1, NUM_SAMPLES);', '                    logger.warn(events);'], 'add': ['import jdk.jfr.consumer.RecordedStackTrace;', 'import java.util.Collections;', 'import java.util.Map;', 'import java.util.stream.Collectors;', '    private static Map&lt;RecordedEvent, Long&gt; coalesce(List&lt;RecordedEvent&gt; events) {', '        Map&lt;RecordedStackTrace, RecordedEvent&gt; stackToEvent = events.stream().collect(', '            Collectors.toMap(RecordedEvent::getStackTrace, e -&gt; e, (e1, e2) -&gt; e1));', '        Map&lt;RecordedStackTrace, Long&gt; coalescedStacks = events.stream().collect(', '            Collectors.groupingBy(RecordedEvent::getStackTrace, Collectors.counting()));', '', '        return coalescedStacks.entrySet().stream().collect(', '            Collectors.toMap(e -&gt; stackToEvent.get(e.getKey()), e -&gt; e.getValue(), (e1, e2) -&gt; e1));', '    }', '', '                logger.warn("Sampling result {}/{}", counter+1, NUM_SAMPLES);', '                    Map&lt;RecordedEvent, Long&gt; coalesced = coalesce(events);', '                    coalesced.entrySet().forEach(e -&gt; {', '                        logger.warn("{} instances of:", e.getValue());', '                        logger.warn(e.getKey());', '                    });', '                } else {', '                    logger.warn("[No long lived objects found]");']}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/80890/commits/f2c6fec58cb9513c8864c590bacff72f43db041d', 'description': ['\n       Remove unused import.\n    '], 'position': ['server/src/main/java/org/elasticsearch/monitor/jvm/OldObjectsSampler.java'], 'code': {'cut': ['import java.util.Collections;'], 'add': []}}, {'commit_id': 'https://github.com/elastic/elasticsearch/pull/80890/commits/3d044dee847c93c1a58ad383e7249a70e188d369', 'description': ['\n       Fix few things for distro.\n    '], 'position': ['server/src/main/java/org/elasticsearch/monitor/jvm/HotThreads.java', 'server/src/main/java/org/elasticsearch/monitor/jvm/OldObjectsSampler.java', 'server/src/main/resources/org/elasticsearch/bootstrap/security.policy'], 'code': {'cut': ['            damnedList.add(new Integer[500_000]);', '                    coalesced.entrySet().forEach(e -&gt; {'], 'add': ['            damnedList.add(new Integer[250_000]);', 'import java.util.Collections;', '                    coalesced.entrySet().stream().sorted(Collections.reverseOrder(Map.Entry.comparingByValue())).forEach(e -&gt; {', '  permission java.lang.RuntimePermission "accessClassInPackage.jdk.internal.event";', '  permission java.lang.RuntimePermission "getClassLoader";']}}], 'title': '[Experiment] Old object sampling when we near Out of Memory '}
    ]
    """

    """
        {
            'origin_url': 'https://github.com/elastic/elasticsearch/pull/92447',
            'comment': 
                [
                    ' Backports the following commits to 8.6:  SQL: fix NPE on logging when not tracking total hits (SQL: fix NPE on logging when not tracking total hits\xa0#92425)  '
                ], 
            'commit_code': 
                [
                    {
                        'commit_id': 'https://github.com/elastic/elasticsearch/pull/92447/commits/74345e759f2729d5778518713a975d1df06cf4ff', 
                        'description': 
                            [
                                    '\n       SQL: fix NPE on logging when not tracking total hits (#92425)\n    '
                            ], 
                        'position': 
                            [
                                'docs/changelog/92425.yaml', 'x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/execution/search/Querier.java'
                            ],
                        'code': 
                            {
                                'cut': 
                                    [
                                        '"Got search response [hits {} {}, {} aggregations: [{}], {} failed shards, {} skipped shards, "', 
                                        '            response.getHits().getTotalHits().relation.toString(),', 
                                        '            response.getHits().getTotalHits().value,'
                                    ], 
                                'add': 
                                    [
                                        'pr: 92425', 'summary: Fix NPE on logging when not tracking total hits', 
                                        'area: SQL', 'type: bug', 'issues: []', 
                                        '        var totalHits = response.getHits().getTotalHits();', 
                                        '        var hits = totalHits != null ? "hits " + totalHits.relation + " " + totalHits.value + ", " : "";', 
                                        '            "Got search response [{}{} aggregations: [{}], {} failed shards, {} skipped shards, "', 
                                        '            hits,'
                                    ]
                            }
                    }
                ], 
            'title': '[8.6] SQL: fix NPE on logging when not tracking total hits (#92425)'
        }
    
    """

    # Áé∞Âú®ÊàëÊúâ‰∏Ä‰∏™ÊÄùË∑ØÔºö
    #   1.ÁõÆÂâçÊù•Áúã‰ºº‰πéÊâæ‰∏çÂà∞cve idÔºåÊàë‰ª¨Ëá™Â∑±Âú®Êü•ÊâæÁöÑËøáÁ®ã‰∏≠ÂÖ∂ÂÆû‰πüÊâæ‰∏çÂà∞cve_id,ÊàñËÄÖÂÖ≥ËÅîÁöÑÂÖ∂‰ªñ‰ªÄ‰πàidÔºåËøô‰∏™‰ø°ÊÅØËøë‰πéÊó†Áî®ÔºåÊâÄ‰ª•Êàë‰ª¨ÂèØ‰ª•ÈÄâÊã©ÊÄßËàçÂºÉËøô‰∏™‰ø°ÊÅØ„ÄÇ
    #   2.Êàë‰ª¨ÂèØ‰ª•ÈááÂèñÁªôÊØè‰∏™commit‰∏ÄÁßçËØÑÂàÜÊú∫Âà∂ÔºåÁÑ∂Âêé‰∏Ä‰∏ÄÊâìÂàÜÔºåËøô‰∏™ÊâìÂàÜÊú∫Âà∂Â∫îÂΩìÊª°Ë∂≥Â¶Ç‰∏ãÁâπÊÄßÔºö
    #       Êàë‰ª¨ÈúÄË¶ÅÊØîËæÉÂÖÖÂàÜÁöÑÂà©Áî®description ÂíåconversitionÁöÑ‰ø°ÊÅØÔºåÂõ†‰∏∫Âú®Â§ßÂ§öÊï∞ÊÉÖÂÜµ‰∏ãÔºåÂè™ÊúâËøô‰∏™‰ø°ÊÅØÊòØÊúâÁî®ÁöÑ
    #       Ëøô‰∏™ÊéíÂêçÊú∫Âà∂ÔºåÂΩìÂá∫Áé∞ÊØîËæÉÂÖ≥ÈîÆÁöÑÊºèÊ¥ûËØçÊ±áÂêéÔºåÊàë‰ª¨Â∫îÂΩìÊääËøô‰∏™ËØçÊ±áÁùÄÈáçÂº∫Ë∞É„ÄÇ
    #       Âà©Áî®codeÁ≠âÊèê‰æõÁöÑ‰ø°ÊÅØ
    #   3.ÊâÄ‰ª•Êàë‰ª¨ÂèØ‰ª•ËøôÊ†∑ËÆæËÆ°Ôºö
    #       ÂØπ‰∫éÊØè‰∏™commitÔºåÁªôÂÆÉÁöÑÊâìÂàÜÂÖ∂ÂÆûÁî±‰∏§ÈÉ®ÂàÜÁªÑÊàêÔºö
    #           1.Ëøô‰∏™commitÊâÄÂΩíÂ±ûÁöÑpullÁöÑÂàÜÊï∞ÔºåËøôÈáå‰∏ªË¶ÅÂà©Áî®pullÁöÑconversion
    #               title
    #               comment
    #           2.Ëøô‰∏™commitËá™Â∑±Â¢ûÂà†ÁöÑ‰ª£Á†Å
    #               commit description
    #                   commit position
    #                   commit code
    #                       code add
    #                       code cut
    #       Êàë‰ª¨ÂÖ∂ÂÆûÊúÄÂÖ≥ÂøÉÁöÑÂú®‰∫éÂíådescription‰∏≠ÁöÑÈáçÂêàÁ®ãÂ∫¶ÔºåËøôÊòØÊàë‰ª¨ÁõÆÂâçÂîØ‰∏ÄÊúâÊïàÁöÑ‰ø°ÊÅØÔºåÊØè‰∏Ä‰∏™ÈáçÂêàÂÖ∂ÂÆûÂèØ‰ª•ÂàÜ‰∏∫‰∏§ÁßçÈáçÂêàÔºö
    #           ÂàÜÂÆåËØç‰ª•ÂêéÁöÑÁ≤óÁï•ÈáçÂêà
    #           Â¶ÇÊûúdescriptionÂíåÊºèÊ¥ûÂÖ≥ÈîÆÂ≠ó‰∏≠ÊúâÈáçÂêàÁöÑËØùÔºåÊàë‰ª¨ËÆ°ÁÆóÊºèÊ¥ûÂÖ≥ÈîÆÂ≠óÁöÑÈáçÂêàÊÉÖÂÜµ
    #       ÂØπ‰∫é‰∏äËø∞‰∏§ÁßçÈáçÂêàÊÉÖÂÜµÔºåËÆ°ÁÆó 1.ÈáçÂêàÂçïËØç‰∏™Êï∞ 2.ËÆ°ÁÆóÈáçÂêàÂçïËØçÊâÄÂç†ÊØî‰æã
    #       Ëøô‰∏§ÈÉ®ÂàÜÂÅöËøêÁÆóÔºåÁ¨¨‰∏ÄÈÉ®ÂàÜÂä†Á¨¨‰∫åÈÉ®ÂàÜÔºåÁÑ∂ÂêéÊàë‰ª¨Ë∞ÉÊï¥‰∏Ä‰∏™ÊùÉÈáçÁ≥ªÊï∞ÔºåÊúÄÁªàËÆ°ÁÆóÂá∫ÊØè‰∏Ä‰∏™commitÁöÑÂæóÂàÜ
    #

    output_commit = []
    for single_commit in pull:
        comment_sentence = ''
        for sentence in single_commit['comment']:
            comment_sentence = comment_sentence + sentence
        comment_set = get_set(comment_sentence)

        common_comment_words_num = len(comment_set.intersection(filtered_word))
        common_comment_words_rate = (common_comment_words_num)/len(comment_set)

        matter_comment_words_num = 0
        matter_comment_words_rate = 0
        if flag_matter_words:
            matter_comment_words_num = len(uion_matterwords.intersection(filtered_word))
            matter_comment_words_rate = (matter_comment_words_num)/len(comment_set)

        title_set = get_set(single_commit['title'])
        common_title_words_num = len(title_set.intersection(filtered_word))
        common_title_words_rate = (common_title_words_num)/len(title_set)

        matter_title_words_num = 0
        matter_title_words_rate = 0
        if flag_matter_words:
            matter_title_words_num = len(uion_matterwords.intersection(title_set))
            matter_title_words_rate = matter_title_words_num/len(title_set)

        base_score = weight['common_comment_words_num']*common_comment_words_num + weight['common_comment_words_rate']*common_comment_words_rate \
                     + matter_comment_words_num*weight['matter_comment_words_num'] + matter_comment_words_rate * weight['matter_comment_words_rate'] +  \
                     common_title_words_num*weight['common_title_words_num'] + common_title_words_rate * weight['common_title_words_rate'] + \
                     matter_title_words_num * weight['matter_title_words_num'] + matter_title_words_rate*weight['matter_title_words_rate']

        # Âà∞ËøôÈáåÊàë‰ª¨Â∑≤ÁªèÊúâ‰∫ÜÂÖ≥‰∫épullÊâìÂàÜÁöÑÂü∫Á°ÄÁöÑÂàÜÂï¶~
        """
        {
                        'commit_id': 'https://github.com/elastic/elasticsearch/pull/92447/commits/74345e759f2729d5778518713a975d1df06cf4ff', 
                        'description': 
                            [
                                    '\n       SQL: fix NPE on logging when not tracking total hits (#92425)\n    '
                            ], 
                        'position': 
                            [
                                'docs/changelog/92425.yaml', 'x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/execution/search/Querier.java'
                            ],
                        'code': 
                            {
                                'cut': 
                                    [
                                        '"Got search response [hits {} {}, {} aggregations: [{}], {} failed shards, {} skipped shards, "', 
                                        '            response.getHits().getTotalHits().relation.toString(),', 
                                        '            response.getHits().getTotalHits().value,'
                                    ], 
                                'add': 
                                    [
                                        'pr: 92425', 'summary: Fix NPE on logging when not tracking total hits', 
                                        'area: SQL', 'type: bug', 'issues: []', 
                                        '        var totalHits = response.getHits().getTotalHits();', 
                                        '        var hits = totalHits != null ? "hits " + totalHits.relation + " " + totalHits.value + ", " : "";', 
                                        '            "Got search response [{}{} aggregations: [{}], {} failed shards, {} skipped shards, "', 
                                        '            hits,'
                                    ]
                            }
                    }
        """
        # ‰∏ãÈù¢Êàë‰ª¨Â∞ÜÂ∞ùËØïÂæóÂà∞ÊØè‰∏™commitËá™Â∑±ÁöÑÂæóÂàÜ~
        for my_commit in single_commit['commit_code']:

            out_commit={
                'commit_id':my_commit['commit_id'],
                'score':None,
                'position':[]
            }

            descs = ''
            for desc in my_commit['description']:
                descs = descs + ' ' + desc
            description_words = get_set(descs)

            common_description_words_num = len(description_words.intersection(filtered_word))
            common_description_words_rate = common_description_words_num/len(description_words)

            matter_description_words_num = 0
            matter_description_words_rate = 0
            if flag_matter_words:
                matter_description_words_num = len(description_words.intersection(uion_matterwords))
                matter_description_words_rate = matter_description_words_num/len(description_words)

            pos = ''
            for positions in my_commit['position']:
                #my_check = positions.split('/')
                x = re.findall('test',positions)
                if len(x) > 0:
                    continue
                y = re.findall('Test',positions)
                if len(y)>0:
                    continue
                out_commit['position'].append(positions)
                pos = pos + ' ' + positions
            pos = pos.replace('/',' ')

            positions_words = get_set(pos)
            if(len(positions_words) == 0):
                common_positions_words_num = 0
                common_positions_words_rate = 0
            else:
                common_positions_words_num = len(positions_words.intersection(filtered_word))
                common_positions_words_rate = common_positions_words_num/len(positions_words)

            matter_position_words_num = 0
            matter_position_words_rate = 0
            if flag_matter_words and len(positions_words) != 0:
                matter_position_words_num = len(positions_words.intersection(uion_matterwords))
                matter_position_words_rate = matter_position_words_num/len(positions_words)

            codes = ''
            for cut in my_commit['code']['cut']:
                codes = codes + ' ' + cut

            for  add in my_commit['code']['add']:
                codes = codes + '' + add

            codes = codes.replace('(',' ').replace(')',' ').replace('[',' ').replace(']',' ')
            codes = codes.replace('{',' ').replace('}',' ')

            code_words = get_set(codes)
            if len(code_words) ==0:
                common_code_words_num = 0
                common_code_words_rate = 0
            else:
                common_code_words_num = len(code_words.intersection(uion_matterwords))
                common_code_words_rate = common_code_words_num/len(code_words)

            matter_code_words_num = 0
            matter_code_words_rate = 0
            if flag_matter_words and len(code_words)!=0:
                matter_code_words_num = len(code_words.intersection(uion_matterwords))
                matter_code_words_rate = matter_code_words_num/len(code_words)

            for_each_score = common_description_words_num * weight['common_description_words_num'] + common_description_words_rate * weight['common_description_words_rate'] + \
                             matter_description_words_num * weight['matter_description_words_num'] + matter_description_words_rate * weight['matter_description_words_rate'] + \
                             common_positions_words_num * weight['common_positions_words_num'] + common_positions_words_rate * weight['common_positions_words_rate'] + \
                             matter_position_words_num * weight['matter_position_words_num'] + matter_position_words_rate * weight['matter_position_words_rate'] + \
                             common_code_words_num * weight['common_code_words_num'] + common_code_words_rate * weight['common_code_words_rate'] + \
                             matter_code_words_num * weight['matter_code_words_num'] + matter_code_words_rate * weight['matter_code_words_rate']

            out_commit['score'] = for_each_score + base_score

            output_commit.append(out_commit)



    output_commit.sort(key=functools.cmp_to_key(compare))
    print(output_commit)
        #print()

    #print(text.replace(u'\xa0', ' '))


